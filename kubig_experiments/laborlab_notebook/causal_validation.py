"""
DoWhy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•œ ì¸ê³¼ëª¨ë¸ êµ¬ì¶•, ì¶”ì •, ê²€ì¦ End-to-End íŒŒì´í”„ë¼ì¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” dummy_data.csvì™€ dummy_graphë¥¼ ì‚¬ìš©í•˜ì—¬
í•™ë ¥ì½”ë“œ(ACCR_CD)ê°€ 180ì¼ì´ë‚´ì·¨ì—…ì—¬ë¶€(ACQ_180_YN)ì— ë¯¸ì¹˜ëŠ” ì¸ê³¼íš¨ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
"""

# =============================================================================
# CONFIG ì„¤ì • ì„¹ì…˜
# =============================================================================

# ë°ì´í„° ë° ê·¸ë˜í”„ ì„¤ì •
DATA_CONFIG = {
    'data_file': 'dummy_data.csv',           # ì‚¬ìš©í•  ë°ì´í„° íŒŒì¼
    'graph_file': 'dummy_graph',             # ì‚¬ìš©í•  ê·¸ë˜í”„ íŒŒì¼
    'treatment': 'ACCR_CD',                  # ì²˜ì¹˜ ë³€ìˆ˜ (í•™ë ¥ì½”ë“œ)
    'outcome': 'ACQ_180_YN',                 # ê²°ê³¼ ë³€ìˆ˜ (180ì¼ì´ë‚´ì·¨ì—…ì—¬ë¶€)
}

# ì¶”ì • ë°©ë²• ì„¤ì •
ESTIMATION_CONFIG = {
    'method': 'backdoor.linear_regression',  # ì¶”ì • ë°©ë²•: linear regression
    'test_significance': True,               # í†µê³„ì  ìœ ì˜ì„± ê²€ì • ìˆ˜í–‰
    'proceed_when_unidentifiable': True,     # ì‹ë³„ ë¶ˆê°€ëŠ¥í•  ë•Œë„ ì§„í–‰
}

# ê²€ì¦ ì„¤ì • -> ì¶”í›„ ìˆ˜ì •í•„ìš”(í˜„ì¬ ê¸°ë³¸ê°’ ì‚¬ìš©)
VALIDATION_CONFIG = {
    'placebo_treatment': {
        'method': 'placebo_treatment_refuter',
        'placebo_type': 'permute',
        'num_simulations': 100
    },
    'unobserved_confounder': {
        'method': 'add_unobserved_common_cause',
        'confounders_effect_on_treatment': 'binary_flip',
        'confounders_effect_on_outcome': 'linear',
        'effect_strength_on_treatment': 0.10,
        'effect_strength_on_outcome': 0.10,
        'num_simulations': 100
    },
    'data_subset': {
        'method': 'data_subset_refuter',
        'subset_fraction': 0.8,
        'num_simulations': 200,
        'random_state': 42
    },
    'dummy_outcome': {
        'method': 'dummy_outcome',
        'num_simulations': 200
    },
    'sensitivity_analysis': {
        'effect_strength_range': (0.0, 0.5),
        'num_points': 11,
        'num_simulations': 200
    }
}

# ì‹œê°í™” ì„¤ì •
VISUALIZATION_CONFIG = {
    'figsize': (10, 8),
    'dpi': 100,
    'save_plots': True,
    'plot_format': 'png'
}

# ë¡œê¹… ì„¤ì •
LOGGING_CONFIG = {
    'save_logs': True,
    'log_format': '%(asctime)s - %(levelname)s - %(message)s',
    'log_level': 20  # logging.INFO = 20
}

# =============================================================================
# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# =============================================================================

import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
from pathlib import Path
import logging
from datetime import datetime
import os

import dowhy
from dowhy import CausalModel

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings("ignore")

# í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™”ìš©)
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# =============================================================================
# ë¡œê¹… ì„¤ì • í•¨ìˆ˜ë“¤
# =============================================================================

def setup_logging(graph_file, treatment, config):
    """
    ë¡œê¹…ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        graph_file (str): ê·¸ë˜í”„ íŒŒì¼ëª…
        treatment (str): ì²˜ì¹˜ ë³€ìˆ˜ëª…
        config (dict): ë¡œê¹… ì„¤ì •
    
    Returns:
        str: ìƒì„±ëœ ë¡œê·¸ íŒŒì¼ëª…
    """
    if not config['save_logs']:
        return None
    
    # ë¡œê·¸ íŒŒì¼ëª… ìƒì„±: ê·¸ë˜í”„ëª…_ì²˜ì¹˜ë³€ìˆ˜_ë‚ ì§œì‹œê°„.log
    graph_name = Path(graph_file).stem  # íŒŒì¼ í™•ì¥ì ì œê±°
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f"{graph_name}_{treatment}_{timestamp}.log"
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=config['log_level'],
        format=config['log_format'],
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler()  # ì½˜ì†”ì—ë„ ì¶œë ¥
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"ë¡œê¹… ì‹œì‘ - ë¡œê·¸ íŒŒì¼: {log_filename}")
    logger.info(f"ê·¸ë˜í”„ íŒŒì¼: {graph_file}")
    logger.info(f"ì²˜ì¹˜ ë³€ìˆ˜: {treatment}")
    logger.info(f"ë¶„ì„ ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    return log_filename

def log_estimation_results(logger, estimate, method_name):
    """
    ì¶”ì • ê²°ê³¼ë¥¼ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        logger: ë¡œê±° ê°ì²´
        estimate: ì¶”ì •ëœ ì¸ê³¼íš¨ê³¼ ê°ì²´
        method_name (str): ì¶”ì • ë°©ë²•ëª…
    """
    logger.info("="*60)
    logger.info("ì¸ê³¼ íš¨ê³¼ ì¶”ì • ê²°ê³¼")
    logger.info("="*60)
    logger.info(f"ì¶”ì • ë°©ë²•: {method_name}")
    logger.info(f"ì¶”ì •ëœ ì¸ê³¼ íš¨ê³¼ (ATE): {estimate.value:.6f}")
    
    if hasattr(estimate, 'p_value') and estimate.p_value is not None:
        logger.info(f"P-value: {estimate.p_value:.6f}")
        significance = "ìœ ì˜í•¨" if estimate.p_value <= 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ"
        logger.info(f"í†µê³„ì  ìœ ì˜ì„±: {significance}")
    
    # ì¶”ì •ì¹˜ì˜ ì‹ ë¢°êµ¬ê°„ì´ ìˆë‹¤ë©´ ë¡œê¹…
    if hasattr(estimate, 'confidence_intervals'):
        logger.info(f"ì‹ ë¢°êµ¬ê°„: {estimate.confidence_intervals}")

def log_validation_results(logger, validation_results):
    """
    ê²€ì¦ ê²°ê³¼ë¥¼ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        logger: ë¡œê±° ê°ì²´
        validation_results (dict): ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    logger.info("="*60)
    logger.info("ê²€ì¦ ê²°ê³¼ ìš”ì•½")
    logger.info("="*60)
    
    # ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸
    if validation_results.get('placebo'):
        placebo = validation_results['placebo']
        effect_change = abs(placebo.new_effect - placebo.estimated_effect)
        status = "í†µê³¼" if effect_change < 0.01 else "ì‹¤íŒ¨"
        logger.info(f"ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸: {status}")
        logger.info(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {placebo.estimated_effect:.6f}")
        logger.info(f"  - ê°€ìƒì²˜ì¹˜ í›„ ì¶”ì •ì¹˜: {placebo.new_effect:.6f}")
        logger.info(f"  - íš¨ê³¼ ë³€í™”: {effect_change:.6f}")
    
    # ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸
    if validation_results.get('unobserved'):
        unobserved = validation_results['unobserved']
        change_rate = abs(unobserved.new_effect - unobserved.estimated_effect) / abs(unobserved.estimated_effect)
        status = "ê°•ê±´í•¨" if change_rate < 0.2 else "ë¯¼ê°í•¨"
        logger.info(f"ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸: {status}")
        logger.info(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {unobserved.estimated_effect:.6f}")
        logger.info(f"  - êµë€ ì¶”ê°€ í›„ ì¶”ì •ì¹˜: {unobserved.new_effect:.6f}")
        logger.info(f"  - ë³€í™”ìœ¨: {change_rate:.2%}")
    
    # ë¶€ë¶„í‘œë³¸ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
    if validation_results.get('subset'):
        subset = validation_results['subset']
        logger.info(f"ë¶€ë¶„í‘œë³¸ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸:")
        logger.info(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {subset.estimated_effect:.6f}")
        logger.info(f"  - ë¶€ë¶„í‘œë³¸ ì¶”ì •ì¹˜: {subset.new_effect:.6f}")
    
    # ë”ë¯¸ ê²°ê³¼ í…ŒìŠ¤íŠ¸
    if validation_results.get('dummy'):
        dummy = validation_results['dummy']
        status = "í†µê³¼" if abs(dummy.new_effect) < 0.01 else "ì‹¤íŒ¨"
        logger.info(f"ë”ë¯¸ ê²°ê³¼ í…ŒìŠ¤íŠ¸: {status}")
        logger.info(f"  - ë”ë¯¸ ê²°ê³¼ ì¶”ì •ì¹˜: {dummy.new_effect:.6f}")

def log_sensitivity_analysis(logger, sensitivity_df, config):
    """
    ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        logger: ë¡œê±° ê°ì²´
        sensitivity_df (pd.DataFrame): ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼
        config (dict): ë¯¼ê°ë„ ë¶„ì„ ì„¤ì •
    """
    logger.info("="*60)
    logger.info("ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼")
    logger.info("="*60)
    
    logger.info(f"íš¨ê³¼ ê°•ë„ ë²”ìœ„: {config['effect_strength_range'][0]} ~ {config['effect_strength_range'][1]}")
    logger.info(f"ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ ìˆ˜: {config['num_points']}")
    logger.info(f"ì‹œë®¬ë ˆì´ì…˜ ìˆ˜: {config['num_simulations']}")
    logger.info(f"ë¶„ì„ëœ ì¡°í•© ìˆ˜: {len(sensitivity_df)}")
    
    if not sensitivity_df.empty:
        logger.info(f"íš¨ê³¼ ë²”ìœ„: {sensitivity_df['new_effect'].min():.6f} ~ {sensitivity_df['new_effect'].max():.6f}")
        
        # íš¨ê³¼ê°€ 0ì— ê°€ê¹Œìš´ ì§€ì  ì°¾ê¸°
        min_abs_effect = sensitivity_df.loc[sensitivity_df['new_effect'].abs().idxmin()]
        logger.info(f"ìµœì†Œ ì ˆëŒ€ íš¨ê³¼ ì§€ì :")
        logger.info(f"  - ì²˜ì¹˜ ê°•ë„ (et): {min_abs_effect['effect_strength_on_treatment']:.2f}")
        logger.info(f"  - ê²°ê³¼ ê°•ë„ (eo): {min_abs_effect['effect_strength_on_outcome']:.2f}")
        logger.info(f"  - íš¨ê³¼ê°’: {min_abs_effect['new_effect']:.6f}")
        
        # íš¨ê³¼ê°€ ìŒìˆ˜ì¸ ì¡°í•© ìˆ˜
        negative_effects = len(sensitivity_df[sensitivity_df['new_effect'] < 0])
        logger.info(f"ìŒìˆ˜ íš¨ê³¼ ì¡°í•© ìˆ˜: {negative_effects} ({negative_effects/len(sensitivity_df)*100:.1f}%)")
        
        # íš¨ê³¼ê°€ 0ì— ê°€ê¹Œìš´ ì¡°í•© ìˆ˜ (ì ˆëŒ€ê°’ < 0.01)
        near_zero_effects = len(sensitivity_df[sensitivity_df['new_effect'].abs() < 0.01])
        logger.info(f"0ì— ê°€ê¹Œìš´ íš¨ê³¼ ì¡°í•© ìˆ˜: {near_zero_effects} ({near_zero_effects/len(sensitivity_df)*100:.1f}%)")

def log_heatmap_info(logger, heatmap_path, config):
    """
    íˆíŠ¸ë§µ ì •ë³´ë¥¼ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        logger: ë¡œê±° ê°ì²´
        heatmap_path (str): íˆíŠ¸ë§µ íŒŒì¼ ê²½ë¡œ
        config (dict): ì‹œê°í™” ì„¤ì •
    """
    logger.info("="*60)
    logger.info("ì‹œê°í™” ê²°ê³¼")
    logger.info("="*60)
    
    if heatmap_path and os.path.exists(heatmap_path):
        file_size = os.path.getsize(heatmap_path)
        logger.info(f"íˆíŠ¸ë§µ íŒŒì¼: {heatmap_path}")
        logger.info(f"íŒŒì¼ í¬ê¸°: {file_size:,} bytes")
        logger.info(f"ì´ë¯¸ì§€ í•´ìƒë„: {config['figsize'][0]}x{config['figsize'][1]} inches")
        logger.info(f"DPI: {config['dpi']}")
    else:
        logger.warning("íˆíŠ¸ë§µ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =============================================================================

def load_data_and_graph(data_file, graph_file):
    """
    ë°ì´í„°ì™€ ê·¸ë˜í”„ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        data_file (str): ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        graph_file (str): ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        tuple: (ë°ì´í„°í”„ë ˆì„, ê·¸ë˜í”„ ë¬¸ìì—´)
    """
    try:
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(data_file)
        print(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {data_file} ({len(df)} í–‰, {len(df.columns)} ì—´)")
        
        # ê·¸ë˜í”„ ë¡œë“œ
        with open(graph_file, 'r', encoding='utf-8') as f:
            causal_graph_gml = f.read()
        print(f"âœ“ ê·¸ë˜í”„ ë¡œë“œ ì™„ë£Œ: {graph_file}")
        
        return df, causal_graph_gml
        
    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        raise
    except Exception as e:
        print(f"âŒ ë°ì´í„°/ê·¸ë˜í”„ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def create_causal_model(df, graph_gml, treatment, outcome):
    """
    ì¸ê³¼ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        df (pd.DataFrame): ë°ì´í„°í”„ë ˆì„
        graph_gml (str): ê·¸ë˜í”„ GML ë¬¸ìì—´
        treatment (str): ì²˜ì¹˜ ë³€ìˆ˜ëª…
        outcome (str): ê²°ê³¼ ë³€ìˆ˜ëª…
    
    Returns:
        CausalModel: DoWhy ì¸ê³¼ëª¨ë¸ ê°ì²´
    """
    try:
        model = CausalModel(
            data=df,
            treatment=treatment,
            outcome=outcome,
            graph=graph_gml
        )
        print(f"âœ“ ì¸ê³¼ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        print(f"  - ì²˜ì¹˜ ë³€ìˆ˜: {treatment}")
        print(f"  - ê²°ê³¼ ë³€ìˆ˜: {outcome}")
        return model
        
    except Exception as e:
        print(f"âŒ ì¸ê³¼ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def identify_effect(model, proceed_when_unidentifiable=True):
    """
    ì¸ê³¼íš¨ê³¼ë¥¼ ì‹ë³„í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        model (CausalModel): ì¸ê³¼ëª¨ë¸ ê°ì²´
        proceed_when_unidentifiable (bool): ì‹ë³„ ë¶ˆê°€ëŠ¥í•  ë•Œë„ ì§„í–‰í• ì§€ ì—¬ë¶€
    
    Returns:
        IdentifiedEstimand: ì‹ë³„ëœ ì¶”ì •ëŸ‰ ê°ì²´
    """
    try:
        identified_estimand = model.identify_effect(
            proceed_when_unidentifiable=proceed_when_unidentifiable
        )
        print("\n" + "="*60)
        print("ğŸ” [ë‹¨ê³„ 1] ì¸ê³¼ íš¨ê³¼ ì‹ë³„ ì™„ë£Œ")
        print("="*60)
        print(identified_estimand)
        return identified_estimand
        
    except Exception as e:
        print(f"âŒ ì¸ê³¼íš¨ê³¼ ì‹ë³„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def estimate_effect(model, identified_estimand, method_name, test_significance=True, logger=None):
    """
    ì¸ê³¼íš¨ê³¼ë¥¼ ì¶”ì •í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        model (CausalModel): ì¸ê³¼ëª¨ë¸ ê°ì²´
        identified_estimand: ì‹ë³„ëœ ì¶”ì •ëŸ‰ ê°ì²´
        method_name (str): ì¶”ì • ë°©ë²•ëª…
        test_significance (bool): í†µê³„ì  ìœ ì˜ì„± ê²€ì • ìˆ˜í–‰ ì—¬ë¶€
        logger: ë¡œê±° ê°ì²´ (ì„ íƒì‚¬í•­)
    
    Returns:
        CausalEstimate: ì¶”ì •ëœ ì¸ê³¼íš¨ê³¼ ê°ì²´
    """
    try:
        estimate = model.estimate_effect(
            identified_estimand,
            method_name=method_name,
            test_significance=test_significance
        )
        
        print("\n" + "="*60)
        print("ğŸ“Š [ë‹¨ê³„ 2] ì¸ê³¼ íš¨ê³¼ ì¶”ì • ì™„ë£Œ")
        print("="*60)
        print(f"  - ì¶”ì • ë°©ë²•: {method_name}")
        print(f"  - ì¶”ì •ëœ ì¸ê³¼ íš¨ê³¼ (ATE): {estimate.value:.6f}")
        
        if hasattr(estimate, 'p_value') and estimate.p_value is not None:
            print(f"  - P-value: {estimate.p_value:.6f}")
            significance = "ìœ ì˜í•¨" if estimate.p_value <= 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ"
            print(f"  - í†µê³„ì  ìœ ì˜ì„±: {significance}")
        
        # ë¡œê¹…
        if logger:
            log_estimation_results(logger, estimate, method_name)
        
        return estimate
        
    except Exception as e:
        print(f"âŒ ì¸ê³¼íš¨ê³¼ ì¶”ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if logger:
            logger.error(f"ì¸ê³¼íš¨ê³¼ ì¶”ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def run_validation_tests(model, identified_estimand, estimate, config, logger=None):
    """
    ë‹¤ì–‘í•œ ê²€ì¦ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        model (CausalModel): ì¸ê³¼ëª¨ë¸ ê°ì²´
        identified_estimand: ì‹ë³„ëœ ì¶”ì •ëŸ‰ ê°ì²´
        estimate: ì¶”ì •ëœ ì¸ê³¼íš¨ê³¼ ê°ì²´
        config (dict): ê²€ì¦ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        logger: ë¡œê±° ê°ì²´ (ì„ íƒì‚¬í•­)
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("\n" + "="*60)
    print("ğŸ”¬ [ë‹¨ê³„ 3] ì¶”ì •ì¹˜ì— ëŒ€í•œ ê°•ê±´ì„± ê²€ì¦ ìˆ˜í–‰")
    print("="*60)
    
    validation_results = {}
    
    # 1. ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸ (Placebo Treatment)
    try:
        print("\nğŸ§ª [ê²€ì¦ 1] ê°€ìƒ ì›ì¸(Placebo Treatment) í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        placebo_config = config['placebo_treatment']
        refute_placebo = model.refute_estimate(
            identified_estimand,
            estimate,
            method_name=placebo_config['method'],
            placebo_type=placebo_config['placebo_type'],
            num_simulations=placebo_config['num_simulations']
        )
        
        print(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {refute_placebo.estimated_effect:.6f}")
        print(f"  - ê°€ìƒì²˜ì¹˜ í›„ ì¶”ì •ì¹˜: {refute_placebo.new_effect:.6f}")
        
        # íš¨ê³¼ í¬ê¸° ë¹„êµ
        effect_change = abs(refute_placebo.new_effect - refute_placebo.estimated_effect)
        if effect_change < 0.01:
            print("  - í•´ì„: ê°€ìƒ ì›ì¸ì˜ íš¨ê³¼ê°€ ê±°ì˜ 0 â†’ ì¶”ì •ì´ ê°•ê±´í•¨ ğŸ‘")
        else:
            print("  - í•´ì„: ê°€ìƒ ì›ì¸ì´ ìœ ì˜í•œ íš¨ê³¼ë¥¼ ë³´ì„ â†’ ì¶”ì • ì„¤ì • ì¬ì ê²€ í•„ìš” ğŸ‘")
        
        validation_results['placebo'] = refute_placebo
        
    except Exception as e:
        print(f"  - ì˜¤ë¥˜ (ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸): {e}")
        validation_results['placebo'] = None
    
    # 2. ë¯¸ê´€ì¸¡ ê³µí†µ ì›ì¸ ì¶”ê°€ í…ŒìŠ¤íŠ¸
    try:
        print("\nğŸ” [ê²€ì¦ 2] ë¯¸ê´€ì¸¡ ê³µí†µ ì›ì¸(Unobserved Common Cause) ì¶”ê°€ í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        unobserved_config = config['unobserved_confounder']
        refute_unobserved = model.refute_estimate(
            identified_estimand,
            estimate,
            method_name=unobserved_config['method'],
            confounders_effect_on_treatment=unobserved_config['confounders_effect_on_treatment'],
            confounders_effect_on_outcome=unobserved_config['confounders_effect_on_outcome'],
            effect_strength_on_treatment=unobserved_config['effect_strength_on_treatment'],
            effect_strength_on_outcome=unobserved_config['effect_strength_on_outcome'],
            num_simulations=unobserved_config['num_simulations']
        )
        
        print(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {refute_unobserved.estimated_effect:.6f}")
        print(f"  - êµë€ ì¶”ê°€ í›„ ì¶”ì •ì¹˜: {refute_unobserved.new_effect:.6f}")
        
        # ë³€í™”ìœ¨ ê³„ì‚°
        change_rate = abs(refute_unobserved.new_effect - refute_unobserved.estimated_effect) / abs(refute_unobserved.estimated_effect)
        print(f"  - ë³€í™”ìœ¨: {change_rate:.2%}")
        
        if change_rate < 0.2:
            print("  - í•´ì„: ë¯¸ê´€ì¸¡ êµë€ì— ë¹„êµì  ê°•ê±´í•¨ ğŸ‘")
        else:
            print("  - í•´ì„: ë¯¸ê´€ì¸¡ êµë€ì— ë¯¼ê°í•¨ â†’ ì¶”ê°€ ë¶„ì„ í•„ìš” ğŸ‘")
        
        validation_results['unobserved'] = refute_unobserved
        
    except Exception as e:
        print(f"  - ì˜¤ë¥˜ (ë¯¸ê´€ì¸¡ ê³µí†µ ì›ì¸ í…ŒìŠ¤íŠ¸): {e}")
        validation_results['unobserved'] = None
    
    # 3. ë¶€ë¶„í‘œë³¸ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
    try:
        print("\nğŸ“Š [ê²€ì¦ 3] ë¶€ë¶„í‘œë³¸ ì•ˆì •ì„±(Data Subset) í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        subset_config = config['data_subset']
        refute_subset = model.refute_estimate(
            identified_estimand,
            estimate,
            method_name=subset_config['method'],
            subset_fraction=subset_config['subset_fraction'],
            num_simulations=subset_config['num_simulations'],
            random_state=subset_config['random_state']
        )
        
        print(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {refute_subset.estimated_effect:.6f}")
        print(f"  - ë¶€ë¶„í‘œë³¸ ì¶”ì •ì¹˜: {refute_subset.new_effect:.6f}")
        
        validation_results['subset'] = refute_subset
        
    except Exception as e:
        print(f"  - ì˜¤ë¥˜ (ë¶€ë¶„í‘œë³¸ í…ŒìŠ¤íŠ¸): {e}")
        validation_results['subset'] = None
    
    # 4. ë”ë¯¸ ê²°ê³¼ ë³€ìˆ˜ í…ŒìŠ¤íŠ¸
    try:
        print("\nğŸ² [ê²€ì¦ 4] ë”ë¯¸ ê²°ê³¼ ë³€ìˆ˜(Dummy Outcome) í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        dummy_config = config['dummy_outcome']
        refute_dummy = model.refute_estimate(
            identified_estimand,
            estimate,
            method_name=dummy_config['method'],
            num_simulations=dummy_config['num_simulations']
        )
        
        print(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {refute_dummy.estimated_effect:.6f}")
        print(f"  - ë”ë¯¸ ê²°ê³¼ ì¶”ì •ì¹˜: {refute_dummy.new_effect:.6f}")
        
        validation_results['dummy'] = refute_dummy
        
    except Exception as e:
        print(f"  - ì˜¤ë¥˜ (ë”ë¯¸ ê²°ê³¼ í…ŒìŠ¤íŠ¸): {e}")
        validation_results['dummy'] = None
    
    # ë¡œê¹…
    if logger:
        log_validation_results(logger, validation_results)
    
    return validation_results

def run_sensitivity_analysis(model, identified_estimand, estimate, config, logger=None):
    """
    ë¯¼ê°ë„ ë¶„ì„ì„ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        model (CausalModel): ì¸ê³¼ëª¨ë¸ ê°ì²´
        identified_estimand: ì‹ë³„ëœ ì¶”ì •ëŸ‰ ê°ì²´
        estimate: ì¶”ì •ëœ ì¸ê³¼íš¨ê³¼ ê°ì²´
        config (dict): ë¯¼ê°ë„ ë¶„ì„ ì„¤ì •
        logger: ë¡œê±° ê°ì²´ (ì„ íƒì‚¬í•­)
    
    Returns:
        pd.DataFrame: ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
    """
    print("\n" + "="*60)
    print("ğŸ“ˆ [ë‹¨ê³„ 4] ë¯¼ê°ë„ ë¶„ì„ ìˆ˜í–‰")
    print("="*60)
    
    try:
        # íš¨ê³¼ ê°•ë„ ê·¸ë¦¬ë“œ ìƒì„±
        effect_range = config['effect_strength_range']
        num_points = config['num_points']
        num_simulations = config['num_simulations']
        
        grid = np.linspace(effect_range[0], effect_range[1], num_points)
        
        print(f"  - íš¨ê³¼ ê°•ë„ ë²”ìœ„: {effect_range[0]} ~ {effect_range[1]}")
        print(f"  - ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ ìˆ˜: {num_points}")
        print(f"  - ì‹œë®¬ë ˆì´ì…˜ ìˆ˜: {num_simulations}")
        print("  - ë¶„ì„ ì§„í–‰ ì¤‘...")
        
        rows = []
        for i, et in enumerate(grid):
            for j, eo in enumerate(grid):
                try:
                    ref = model.refute_estimate(
                        identified_estimand, estimate,
                        method_name="add_unobserved_common_cause",
                        confounders_effect_on_treatment="binary_flip",
                        confounders_effect_on_outcome="linear",
                        effect_strength_on_treatment=et,
                        effect_strength_on_outcome=eo,
                        num_simulations=num_simulations
                    )
                    rows.append((et, eo, ref.new_effect))
                except Exception as e:
                    print(f"    - ì˜¤ë¥˜ (et={et:.2f}, eo={eo:.2f}): {e}")
                    rows.append((et, eo, np.nan))
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        sensitivity_df = pd.DataFrame(rows, columns=[
            "effect_strength_on_treatment", 
            "effect_strength_on_outcome", 
            "new_effect"
        ])
        
        print(f"âœ“ ë¯¼ê°ë„ ë¶„ì„ ì™„ë£Œ: {len(sensitivity_df)} ê°œ ì¡°í•© ë¶„ì„")
        
        # ë¡œê¹…
        if logger:
            log_sensitivity_analysis(logger, sensitivity_df, config)
        
        return sensitivity_df
        
    except Exception as e:
        print(f"âŒ ë¯¼ê°ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if logger:
            logger.error(f"ë¯¼ê°ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

def create_sensitivity_heatmap(sensitivity_df, config, logger=None):
    """
    ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ë¥¼ íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        sensitivity_df (pd.DataFrame): ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼
        config (dict): ì‹œê°í™” ì„¤ì •
        logger: ë¡œê±° ê°ì²´ (ì„ íƒì‚¬í•­)
    
    Returns:
        tuple: (matplotlib.figure.Figure, str) ìƒì„±ëœ ê·¸ë¦¼ ê°ì²´ì™€ íŒŒì¼ ê²½ë¡œ
    """
    if sensitivity_df.empty:
        print("âŒ ë¯¼ê°ë„ ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ íˆíŠ¸ë§µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        print("\nğŸ¨ ë¯¼ê°ë„ ë¶„ì„ íˆíŠ¸ë§µ ìƒì„± ì¤‘...")
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„±
        pivot = sensitivity_df.pivot(
            index="effect_strength_on_treatment",
            columns="effect_strength_on_outcome",
            values="new_effect"
        ).sort_index(ascending=True)
        
        # íˆíŠ¸ë§µ ìƒì„±
        fig, ax = plt.subplots(figsize=config['figsize'], dpi=config['dpi'])
        
        # íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°
        im = ax.imshow(
            pivot.values,
            origin="lower",
            aspect="auto",
            extent=[
                pivot.columns.min(), pivot.columns.max(),
                pivot.index.min(), pivot.index.max()
            ],
            cmap='RdYlBu_r'
        )
        
        # ìƒ‰ìƒë§‰ëŒ€ ì¶”ê°€
        cbar = plt.colorbar(im, ax=ax)
        cbar.set_label("New Effect (after unobserved confounding)", fontsize=12)
        
        # 0-ì»¨íˆ¬ì–´ ë¼ì¸ ì¶”ê°€
        X, Y = np.meshgrid(pivot.columns.values, pivot.index.values)
        CS = ax.contour(X, Y, pivot.values, levels=[0.0], linewidths=2, colors='black')
        ax.clabel(CS, inline=True, fmt="effect=0", fontsize=10)
        
        # ìµœì†Œ ì ˆëŒ€ê°’ ì§€ì  ë§ˆì»¤
        abs_min_idx = np.unravel_index(
            np.nanargmin(np.abs(pivot.values)), 
            pivot.values.shape
        )
        et_star = pivot.index.values[abs_min_idx[0]]
        eo_star = pivot.columns.values[abs_min_idx[1]]
        ax.plot(eo_star, et_star, marker="o", markersize=8, color='red')
        ax.annotate(
            f"Min effect at (et={et_star:.2f}, eo={eo_star:.2f})",
            (eo_star, et_star), 
            xytext=(10, 10), 
            textcoords="offset points", 
            fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7)
        )
        
        # ì¶• ë ˆì´ë¸” ë° ì œëª©
        ax.set_xlabel("Effect Strength on Outcome (eo)", fontsize=12)
        ax.set_ylabel("Effect Strength on Treatment (et)", fontsize=12)
        ax.set_title("Sensitivity Analysis: Effect of Unobserved Confounders", fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        # ê·¸ë¦¼ ì €ì¥
        output_path = None
        if config['save_plots']:
            output_path = f"sensitivity_heatmap.{config['plot_format']}"
            plt.savefig(output_path, dpi=config['dpi'], bbox_inches='tight')
            print(f"âœ“ íˆíŠ¸ë§µ ì €ì¥ ì™„ë£Œ: {output_path}")
        
        plt.show()
        
        # ë¡œê¹…
        if logger:
            log_heatmap_info(logger, output_path, config)
        
        return fig, output_path
        
    except Exception as e:
        print(f"âŒ íˆíŠ¸ë§µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if logger:
            logger.error(f"íˆíŠ¸ë§µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

def print_summary_report(estimate, validation_results, sensitivity_df):
    """
    ì „ì²´ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        estimate: ì¶”ì •ëœ ì¸ê³¼íš¨ê³¼ ê°ì²´
        validation_results (dict): ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        sensitivity_df (pd.DataFrame): ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼
    """
    print("\n" + "="*80)
    print("ğŸ“‹ ìµœì¢… ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œ")
    print("="*80)
    
    # ê¸°ë³¸ ì¶”ì • ê²°ê³¼
    print(f"\nğŸ¯ ì£¼ìš” ì¶”ì • ê²°ê³¼:")
    print(f"  - ì¶”ì •ëœ ì¸ê³¼ íš¨ê³¼ (ATE): {estimate.value:.6f}")
    if hasattr(estimate, 'p_value') and estimate.p_value is not None:
        significance = "ìœ ì˜í•¨" if estimate.p_value <= 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ"
        print(f"  - í†µê³„ì  ìœ ì˜ì„±: {significance} (p-value: {estimate.p_value:.6f})")
    
    # ê²€ì¦ ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ”¬ ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
    
    if validation_results.get('placebo'):
        placebo = validation_results['placebo']
        effect_change = abs(placebo.new_effect - placebo.estimated_effect)
        print(f"  - ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸: {'í†µê³¼' if effect_change < 0.01 else 'ì‹¤íŒ¨'}")
    
    if validation_results.get('unobserved'):
        unobserved = validation_results['unobserved']
        change_rate = abs(unobserved.new_effect - unobserved.estimated_effect) / abs(unobserved.estimated_effect)
        print(f"  - ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸: {'ê°•ê±´í•¨' if change_rate < 0.2 else 'ë¯¼ê°í•¨'}")
    
    if validation_results.get('subset'):
        subset = validation_results['subset']
        print(f"  - ë¶€ë¶„í‘œë³¸ ì•ˆì •ì„±: ì¶”ì •ì¹˜ ë³€í™” í™•ì¸ë¨")
    
    if validation_results.get('dummy'):
        dummy = validation_results['dummy']
        print(f"  - ë”ë¯¸ ê²°ê³¼ í…ŒìŠ¤íŠ¸: {'í†µê³¼' if abs(dummy.new_effect) < 0.01 else 'ì‹¤íŒ¨'}")
    
    # ë¯¼ê°ë„ ë¶„ì„ ìš”ì•½
    if not sensitivity_df.empty:
        print(f"\nğŸ“ˆ ë¯¼ê°ë„ ë¶„ì„ ìš”ì•½:")
        print(f"  - ë¶„ì„ëœ ì¡°í•© ìˆ˜: {len(sensitivity_df)}")
        print(f"  - íš¨ê³¼ ë²”ìœ„: {sensitivity_df['new_effect'].min():.6f} ~ {sensitivity_df['new_effect'].max():.6f}")
        
        # íš¨ê³¼ê°€ 0ì— ê°€ê¹Œìš´ ì§€ì  ì°¾ê¸°
        min_abs_effect = sensitivity_df.loc[sensitivity_df['new_effect'].abs().idxmin()]
        print(f"  - ìµœì†Œ ì ˆëŒ€ íš¨ê³¼ ì§€ì : et={min_abs_effect['effect_strength_on_treatment']:.2f}, eo={min_abs_effect['effect_strength_on_outcome']:.2f}")
    
    print(f"\nâœ… ì „ì²´ ë¶„ì„ ì™„ë£Œ!")

# =============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("ğŸš€ DoWhy ì¸ê³¼ëª¨ë¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("="*80)
    
    # ë¡œê¹… ì„¤ì •
    log_filename = setup_logging(
        DATA_CONFIG['graph_file'], 
        DATA_CONFIG['treatment'], 
        LOGGING_CONFIG
    )
    logger = logging.getLogger(__name__) if log_filename else None
    
    try:
        # 1. ë°ì´í„° ë° ê·¸ë˜í”„ ë¡œë“œ
        df, causal_graph_gml = load_data_and_graph(
            DATA_CONFIG['data_file'], 
            DATA_CONFIG['graph_file']
        )
        
        # 2. ì¸ê³¼ëª¨ë¸ ìƒì„±
        model = create_causal_model(
            df, 
            causal_graph_gml, 
            DATA_CONFIG['treatment'], 
            DATA_CONFIG['outcome']
        )
        
        # 3. ì¸ê³¼íš¨ê³¼ ì‹ë³„
        identified_estimand = identify_effect(
            model, 
            ESTIMATION_CONFIG['proceed_when_unidentifiable']
        )
        
        # 4. ì¸ê³¼íš¨ê³¼ ì¶”ì •
        estimate = estimate_effect(
            model,
            identified_estimand,
            ESTIMATION_CONFIG['method'],
            ESTIMATION_CONFIG['test_significance'],
            logger
        )
        
        # 5. ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        validation_results = run_validation_tests(
            model, 
            identified_estimand, 
            estimate, 
            VALIDATION_CONFIG,
            logger
        )
        
        # 6. ë¯¼ê°ë„ ë¶„ì„
        sensitivity_df = run_sensitivity_analysis(
            model, 
            identified_estimand, 
            estimate, 
            VALIDATION_CONFIG['sensitivity_analysis'],
            logger
        )
        
        # 7. ë¯¼ê°ë„ ë¶„ì„ íˆíŠ¸ë§µ ìƒì„±
        heatmap_path = None
        if not sensitivity_df.empty:
            _, heatmap_path = create_sensitivity_heatmap(sensitivity_df, VISUALIZATION_CONFIG, logger)
        
        # 8. ìµœì¢… ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥
        print_summary_report(estimate, validation_results, sensitivity_df)
        
        # 9. ë¡œê¹… ì™„ë£Œ ë©”ì‹œì§€
        if logger:
            logger.info("="*60)
            logger.info("ë¶„ì„ ì™„ë£Œ")
            logger.info("="*60)
            logger.info(f"ë¶„ì„ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            if log_filename:
                logger.info(f"ë¡œê·¸ íŒŒì¼: {log_filename}")
            if heatmap_path:
                logger.info(f"íˆíŠ¸ë§µ íŒŒì¼: {heatmap_path}")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if logger:
            logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

if __name__ == "__main__":
    main()
