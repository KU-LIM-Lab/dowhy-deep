# íì‡ ë§(ì˜¤í”„ë¼ì¸) í™˜ê²½ êµ¬ì¶• ê°€ì´ë“œ

## âš ï¸ í˜„ì¬ ìƒíƒœ ë¶„ì„

**í˜„ì¬ ì„¤ì •ì€ ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**

ë‹¤ìŒ ë¶€ë¶„ë“¤ì´ ì¸í„°ë„· ì—°ê²°ì„ í•„ìš”ë¡œ í•©ë‹ˆë‹¤:
1. `Dockerfile`ì˜ `apt-get update` (ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ)
2. `Dockerfile`ì˜ `pip install` (Python íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ)
3. `docker-compose.yml`ì˜ `ollama/ollama:latest` ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
4. ë² ì´ìŠ¤ ì´ë¯¸ì§€ `nvidia/cuda:12.4.0-runtime-ubuntu22.04` ë‹¤ìš´ë¡œë“œ

## ğŸ“¦ ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•  íŒŒì¼ë“¤

### 1. Docker ì´ë¯¸ì§€

#### 1.1 ë² ì´ìŠ¤ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
```bash
# CUDA ë² ì´ìŠ¤ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
docker pull nvidia/cuda:12.4.0-runtime-ubuntu22.04
docker save nvidia/cuda:12.4.0-runtime-ubuntu22.04 -o nvidia-cuda-12.4.0-runtime-ubuntu22.04.tar

# ì´ë¯¸ì§€ í¬ê¸°: ì•½ 2-3GB
```

#### 1.2 Ollama ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
```bash
# Ollama ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
docker pull ollama/ollama:latest
docker save ollama/ollama:latest -o ollama-latest.tar

# ì´ë¯¸ì§€ í¬ê¸°: ì•½ 1-2GB
```

#### 1.3 ë¹Œë“œëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ë¯¸ì§€ ì €ì¥ (ì„ íƒì‚¬í•­)
```bash
# ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ ë¹Œë“œ í›„ ì €ì¥
docker-compose build
docker save laborlab-2-analysis:latest -o laborlab-2-image.tar

# ë˜ëŠ” docker-composeë¡œ ë¹Œë“œëœ ì´ë¯¸ì§€ í™•ì¸
docker images | grep laborlab
```

### 2. Python íŒ¨í‚¤ì§€ (Wheel íŒŒì¼)

#### 2.1 íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë“  íŒ¨í‚¤ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ:

```bash
# requirements.txtì˜ ëª¨ë“  íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ
pip download -r requirements.txt -d ./offline_packages --platform linux_x86_64 --only-binary :all:

# ë˜ëŠ” ì†ŒìŠ¤ ë°°í¬ë³¸ë„ í¬í•¨í•˜ë ¤ë©´
pip download -r requirements.txt -d ./offline_packages

# TabPFN íŠ¹ë³„ ì²˜ë¦¬ (GitHubì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ í•„ìš”)
# TabPFNì€ requirements.txtì— ì£¼ì„ ì²˜ë¦¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬ í•„ìš”
```

#### 2.2 í•„ìš”í•œ Python íŒ¨í‚¤ì§€ ëª©ë¡
`requirements.txt`ì— ëª…ì‹œëœ íŒ¨í‚¤ì§€ë“¤:
- numpy>=2.0.0
- pandas>=2.0.0
- scikit-learn>=1.0.0
- scipy>=1.10.0
- statsmodels>=0.14.0
- networkx>=3.3.0
- sympy>=1.10.1
- joblib>=1.1.0
- tqdm>=4.64.0
- causal-learn>=0.1.3.0
- econml>=0.16.0
- numba>=0.59.0
- torch>=2.0.0 (PyTorch - ë§¤ìš° í¼, ì•½ 1-2GB)
- tabpfn>=0.1.0
- matplotlib>=3.5.3
- pydot>=1.4.2
- python-dateutil>=2.8.0
- openpyxl>=3.1.0
- openai>=1.0.0
- ollama>=0.1.0

**ì˜ˆìƒ ì´ í¬ê¸°: ì•½ 5-10GB** (PyTorch í¬í•¨)

#### 2.3 TabPFN íŠ¹ë³„ ì²˜ë¦¬
TabPFNì€ GitHubì—ì„œ ì§ì ‘ ì„¤ì¹˜í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
```bash
# TabPFN ì†ŒìŠ¤ ì½”ë“œ ë‹¤ìš´ë¡œë“œ
git clone https://github.com/PriorLabs/TabPFN.git
cd TabPFN
git checkout 86bad3f492d72d849c583d57f0ddda8ea3216ed0
cd ..
tar -czf TabPFN-source.tar.gz TabPFN/
```

### 3. APT íŒ¨í‚¤ì§€ (Ubuntu 22.04)

#### 3.1 í•„ìš”í•œ ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ëª©ë¡
Dockerfileì—ì„œ ì„¤ì¹˜í•˜ëŠ” íŒ¨í‚¤ì§€ë“¤:
- python3.11
- python3.11-dev
- python3-pip
- gcc
- g++
- make
- git
- curl

#### 3.2 APT íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ
```bash
# Ubuntu 22.04 í™˜ê²½ì—ì„œ ì‹¤í–‰
mkdir -p ./offline_apt_packages
cd ./offline_apt_packages

# íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ (ì˜ì¡´ì„± í¬í•¨)
apt-get download python3.11 python3.11-dev python3-pip gcc g++ make git curl

# ëª¨ë“  ì˜ì¡´ì„± ë‹¤ìš´ë¡œë“œ
apt-get install --download-only python3.11 python3.11-dev python3-pip gcc g++ make git curl

# ë˜ëŠ” apt-offline ì‚¬ìš© (ë” íš¨ìœ¨ì )
apt-offline set offline_packages.sig --install-packages python3.11 python3.11-dev python3-pip gcc g++ make git curl
apt-offline get offline_packages.sig --bundle offline_packages.zip
```

### 4. Ollama ëª¨ë¸ íŒŒì¼ (ì„ íƒì‚¬í•­)

LLM ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°:
```bash
# Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ)
# ì˜ˆ: llama2, mistral ë“±
# ì´ëŠ” ì»¨í…Œì´ë„ˆ ì‹¤í–‰ í›„ ollama pull ëª…ë ¹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥
# ë˜ëŠ” ./ollama_models ë””ë ‰í† ë¦¬ì— ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œ
```

## ğŸš€ ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œì˜ ì„¤ì • ë°©ë²•

### ë°©ë²• 1: Docker ì´ë¯¸ì§€ ë¯¸ë¦¬ ë¹Œë“œ (ê¶Œì¥)

#### 1.1 ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ
```bash
# 1. ëª¨ë“  íŒŒì¼ ì¤€ë¹„
mkdir -p offline_resources
cd offline_resources

# 2. Docker ì´ë¯¸ì§€ ì €ì¥
docker pull nvidia/cuda:12.4.0-runtime-ubuntu22.04
docker save nvidia/cuda:12.4.0-runtime-ubuntu22.04 -o nvidia-cuda.tar

docker pull ollama/ollama:latest
docker save ollama/ollama:latest -o ollama.tar

# 3. Python íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ
pip download -r ../laborlab_2/requirements.txt -d ./python_packages --platform linux_x86_64

# 4. APT íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ (Ubuntu 22.04)
apt-get download python3.11 python3.11-dev python3-pip gcc g++ make git curl
# ë˜ëŠ” apt-offline ì‚¬ìš©

# 5. ì „ì²´ë¥¼ ì••ì¶•
tar -czf offline_resources.tar.gz .
```

#### 1.2 ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ
```bash
# 1. ë¦¬ì†ŒìŠ¤ ì••ì¶• í•´ì œ
tar -xzf offline_resources.tar.gz

# 2. Docker ì´ë¯¸ì§€ ë¡œë“œ
docker load < nvidia-cuda.tar
docker load < ollama.tar

# 3. Dockerfile ìˆ˜ì • í•„ìš” (ì•„ë˜ ì°¸ì¡°)
# 4. docker-compose build ì‹¤í–‰
```

### ë°©ë²• 2: Dockerfile ìˆ˜ì • (ì˜¤í”„ë¼ì¸ ëŒ€ì‘)

Dockerfileì„ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤:

```dockerfile
# CUDA 12.4 ê¸°ë°˜ ì´ë¯¸ì§€ ì‚¬ìš© (Ubuntu 22.04)
FROM nvidia/cuda:12.4.0-runtime-ubuntu22.04

# ë¡œì»¬ APT íŒ¨í‚¤ì§€ ë³µì‚¬ ë° ì„¤ì¹˜
COPY offline_apt_packages/*.deb /tmp/apt_packages/
RUN dpkg -i /tmp/apt_packages/*.deb || true && \
    apt-get update --allow-insecure-repositories && \
    apt-get install -f -y --allow-unauthenticated && \
    rm -rf /var/lib/apt/lists/*

# python3.11ì„ ê¸°ë³¸ pythonìœ¼ë¡œ ì„¤ì •
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1
RUN update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ë³µì‚¬
COPY . /app/

# ë¡œì»¬ Python íŒ¨í‚¤ì§€ ë³µì‚¬
COPY offline_packages /tmp/pip_packages

# Python ì˜ì¡´ì„± ì„¤ì¹˜ (ë¡œì»¬ íŒ¨í‚¤ì§€ ì‚¬ìš©)
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir --find-links /tmp/pip_packages --no-index -r /app/laborlab_2/requirements.txt && \
    pip install --no-cache-dir -e /app

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV PYTHONPATH=/app
ENV TERMINAL_OUTPUT_DIR=/app/laborlab_2/log

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app/laborlab_2

# ê¸°ë³¸ ëª…ë ¹ì–´: main.py ì‹¤í–‰
CMD ["python", "-m", "src.main", "--config", "config.json"]
```

### ë°©ë²• 3: docker-compose.yml ìˆ˜ì •

```yaml
  ollama:
    container_name: ollama
    # image ëŒ€ì‹  build ì‚¬ìš©í•˜ê±°ë‚˜, ë¯¸ë¦¬ ë¡œë“œëœ ì´ë¯¸ì§€ ì‚¬ìš©
    image: ollama/ollama:latest  # ì´ë¯¸ docker loadë¡œ ë¡œë“œëœ ì´ë¯¸ì§€ ì‚¬ìš©
    # ë˜ëŠ”
    # build:
    #   context: ./ollama_build
    #   dockerfile: Dockerfile.ollama
```

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ ì¤€ë¹„í•  í•­ëª©:

- [ ] `nvidia/cuda:12.4.0-runtime-ubuntu22.04` Docker ì´ë¯¸ì§€ (tar íŒŒì¼)
- [ ] `ollama/ollama:latest` Docker ì´ë¯¸ì§€ (tar íŒŒì¼)
- [ ] Python íŒ¨í‚¤ì§€ wheel íŒŒì¼ë“¤ (requirements.txt ê¸°ë°˜)
- [ ] APT íŒ¨í‚¤ì§€ deb íŒŒì¼ë“¤ (Ubuntu 22.04)
- [ ] TabPFN ì†ŒìŠ¤ ì½”ë“œ (í•„ìš”í•œ ê²½ìš°)
- [ ] Ollama ëª¨ë¸ íŒŒì¼ë“¤ (í•„ìš”í•œ ê²½ìš°)

### ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ìˆ˜í–‰í•  ì‘ì—…:

- [ ] Docker ì´ë¯¸ì§€ ë¡œë“œ (`docker load`)
- [ ] Dockerfile ìˆ˜ì • (ë¡œì»¬ íŒ¨í‚¤ì§€ ê²½ë¡œ ì§€ì •)
- [ ] docker-compose.yml í™•ì¸
- [ ] ë¹Œë“œ í…ŒìŠ¤íŠ¸ (`docker-compose build`)
- [ ] ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (`docker-compose up`)

## ğŸ” ê²€ì¦ ë°©ë²•

ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ê²€ì¦:

```bash
# 1. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì°¨ë‹¨ í™•ì¸
ping 8.8.8.8  # ì‹¤íŒ¨í•´ì•¼ í•¨

# 2. Docker ì´ë¯¸ì§€ ë¡œë“œ
docker load < nvidia-cuda.tar
docker load < ollama.tar

# 3. ì´ë¯¸ì§€ í™•ì¸
docker images

# 4. ë¹Œë“œ í…ŒìŠ¤íŠ¸
docker-compose build --no-cache

# 5. ì‹¤í–‰ í…ŒìŠ¤íŠ¸
docker-compose up
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **í”Œë«í¼ í˜¸í™˜ì„±**: Python wheel íŒŒì¼ì€ Linux x86_64ìš©ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.
2. **ì˜ì¡´ì„± í•´ê²°**: ì¼ë¶€ íŒ¨í‚¤ì§€ëŠ” ë³µì¡í•œ ì˜ì¡´ì„±ì„ ê°€ì§€ë¯€ë¡œ ëª¨ë“  ì˜ì¡´ì„±ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
3. **CUDA ë²„ì „**: í˜¸ìŠ¤íŠ¸ ì‹œìŠ¤í…œì˜ CUDA ë²„ì „ê³¼ Docker ì´ë¯¸ì§€ì˜ CUDA ë²„ì „ì´ í˜¸í™˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
4. **ë””ìŠ¤í¬ ê³µê°„**: ì „ì²´ ë¦¬ì†ŒìŠ¤ëŠ” ì•½ 15-20GB ì •ë„ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

