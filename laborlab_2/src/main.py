"""
LaborLab 2 - ì¸ê³¼ì¶”ë¡  ë¶„ì„ ë©”ì¸ íŒŒì´í”„ë¼ì¸

ì „ì²´ íŒŒì´í”„ë¼ì¸:
1. ê²½ë¡œë¥¼ í†µí•´ ë°ì´í„° ë¡œë“œ
1-1. (Test mode) ì „ì²˜ë¦¬ê³¼ì •ì´ ì˜ ë˜ëŠ”ì§€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ ë¡œë“œëœ ë°ì´í„°ì˜ ì•ì—ì„œ 5000ê°œë§Œ ì˜ë¼ì„œ ì‚¬ìš©
2. ë°ì´í„° ì „ì²˜ë¦¬
3. ë°ì´í„° ë³‘í•©
4. train test split (1:99)
5. causal graph ë¡œë“œí•´ì„œ ì‹¤í—˜ì •ì˜
6. ê° ì‹¤í—˜ë³„ estimation - refutation - prediction ì§„í–‰ í›„ ê²°ê³¼ì €ì¥
"""
import argparse
import pandas as pd
import warnings
from pathlib import Path
import os
import time
import itertools
from typing import Dict, Any, List, Tuple, Optional

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings("ignore")

# DoWhy ë¡œê±° ë ˆë²¨ ì„¤ì •
import logging as dowhy_logging
dowhy_logging.getLogger("dowhy.causal_estimator").setLevel(dowhy_logging.WARNING)
dowhy_logging.getLogger("dowhy.causal_estimators").setLevel(dowhy_logging.WARNING)

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì„í¬íŠ¸
from .utils import (
    load_all_data,
    preprocess_and_merge_data,
    clean_dataframe_for_causal_model,
    create_causal_graph,
    extract_treatments_from_graph,
    find_all_graph_files,
    setup_logging,
    load_config,
    run_single_experiment,
    run_inference
)
from datetime import datetime
import json


def preprocess(
    data_dir_path: Path,
    seis_data_dir: str,
    limit_data: bool = False,
    limit_size: int = 5000,
    job_category_file: str = "KSIC"
) -> pd.DataFrame:
    """
    ì „ì²˜ë¦¬ í•¨ìˆ˜ (limit_data ì˜µì…˜ìœ¼ë¡œ ë°ì´í„° ì œí•œ ê°€ëŠ¥)
    
    Args:
        data_dir_path: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        seis_data_dir: seis_data ë””ë ‰í† ë¦¬ëª…
        limit_data: ë°ì´í„° ì œí•œ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        limit_size: ì œí•œí•  ë°ì´í„° í¬ê¸° (ê¸°ë³¸ê°’: 5000)
        job_category_file: ì§ì¢… ì†Œë¶„ë¥˜ íŒŒì¼ëª… (KECO, KSCO, KSIC ì¤‘ ì„ íƒ, ê¸°ë³¸ê°’: KSIC)
    
    Returns:
        merged_df: ì „ì²˜ë¦¬ ë° ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„
    """
    print("="*80)
    print("1ï¸âƒ£ ë°ì´í„° ë¡œë“œ ì‹œì‘")
    print("="*80)
    
    file_list, causal_graph = load_all_data(
        str(data_dir_path), 
        seis_data_dir, 
        graph_file=None
    )
    
    print("\n" + "="*80)
    if limit_data:
        print("2ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬ ë° 3ï¸âƒ£ ë°ì´í„° ë³‘í•© ì‹œì‘ (ì œí•œ ëª¨ë“œ)")
        print(f"\n(Test mode): ì „ì²˜ë¦¬ ì „ì— ê° íŒŒì¼ì—ì„œ ì• {limit_size}ê°œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        print("2ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬ ë° 3ï¸âƒ£ ë°ì´í„° ë³‘í•© ì‹œì‘")
    print("="*80)
    
    print(f"ğŸ“‹ ì‚¬ìš©í•  ì§ì¢… ì†Œë¶„ë¥˜ íŒŒì¼: job_subcategories_{job_category_file}.csv")
    print("âš¡ JSON íŒŒì¼ 4ê°œ(ì´ë ¥ì„œ, ìê¸°ì†Œê°œì„œ, ì§ì—…í›ˆë ¨, ìê²©ì¦) ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")
    preprocessing_start = time.time()
    
    merged_df = preprocess_and_merge_data(
        file_list, 
        str(data_dir_path), 
        limit_data=limit_data, 
        limit_size=limit_size,
        job_category_file=job_category_file
    )
    print(f"âœ… ìµœì¢… ë³‘í•© ë°ì´í„°: {len(merged_df)}ê±´, {len(merged_df.columns)}ê°œ ë³€ìˆ˜")
    
    preprocessing_elapsed = time.time() - preprocessing_start
    print(f"â±ï¸ ì „ì²˜ë¦¬ ë° ë³‘í•© ì™„ë£Œ! ì†Œìš” ì‹œê°„: {preprocessing_elapsed:.2f}ì´ˆ")
    
    return merged_df


def learning(
    merged_df_clean: pd.DataFrame,
    graph_file: str,
    treatment: str,
    outcome: str,
    estimator: str = "tabpfn",
    experiment_id: Optional[str] = None,
    logger: Optional[Any] = None
) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ì‹¤í—˜ì— ëŒ€í•œ learning í•¨ìˆ˜
    ë‹¨ì¼ ê·¸ë˜í”„, íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸, estimatorë¡œ í•œ ë²ˆì˜ estimation(fitting) ë° refutationì„ ì§„í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¡œê¹…
    
    Args:
        merged_df_clean: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        graph_file: ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
        treatment: íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ ë³€ìˆ˜ëª…
        outcome: ê²°ê³¼ ë³€ìˆ˜ëª…
        estimator: ì¶”ì • ë°©ë²• (ê¸°ë³¸ê°’: tabpfn)
        experiment_id: ì‹¤í—˜ ID (ì„ íƒì )
        logger: ë¡œê±° ê°ì²´ (ì„ íƒì )
    
    Returns:
        ì‹¤í—˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if experiment_id is None:
        experiment_id = f"{Path(graph_file).stem}_{treatment}_{outcome}_{estimator}"
    
    print(f"\n{'='*80}")
    print(f"ğŸ“ Learning ì‹¤í–‰ - {experiment_id}")
    print(f"ê·¸ë˜í”„: {Path(graph_file).name}")
    print(f"Treatment: {treatment}, Outcome: {outcome}, Estimator: {estimator}")
    print(f"{'='*80}\n")
    
    result = run_single_experiment(
        merged_df_clean=merged_df_clean,
        graph_file=graph_file,
        treatment=treatment,
        outcome=outcome,
        estimator=estimator,
        experiment_id=experiment_id,
        logger=logger
    )
    
    if result["status"] == "success":
        print(f"âœ… Learning ì™„ë£Œ: {experiment_id}")
        print(f"   ATE ê°’: {result.get('ate_value', 'N/A')}")
        print(f"   F1 Score: {result.get('f1_score', 'N/A')}")
        print(f"   AUC: {result.get('auc', 'N/A')}")
    else:
        print(f"âŒ Learning ì‹¤íŒ¨: {experiment_id}")
        if result.get("error"):
            print(f"   ì—ëŸ¬: {result['error']}")
    
    return result


def _save_result_to_csv(
    csv_file: Path,
    csv_columns: List[str],
    csv_row: Dict[str, Any]
) -> None:
    """
    CSV íŒŒì¼ì— ê²°ê³¼ë¥¼ ì¶”ê°€í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜
    
    Args:
        csv_file: CSV íŒŒì¼ ê²½ë¡œ
        csv_columns: CSV ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        csv_row: ì¶”ê°€í•  í–‰ ë°ì´í„°
    """
    try:
        existing_df = pd.read_csv(csv_file, encoding='utf-8-sig')
    except (FileNotFoundError, pd.errors.EmptyDataError):
        existing_df = pd.DataFrame(columns=csv_columns)
    
    new_row_df = pd.DataFrame([csv_row])
    updated_df = pd.concat([existing_df, new_row_df], ignore_index=True)
    updated_df.to_csv(csv_file, index=False, encoding='utf-8-sig')


def _run_experiments_batch(
    experiment_list: List[Tuple[str, str, str, str]],
    experiment_func,
    experiment_type: str,
    merged_df_clean: pd.DataFrame,
    logger: Optional[Any] = None,
    output_dir: Optional[Path] = None,
    **kwargs
) -> List[Dict[str, Any]]:
    """
    ì‹¤í—˜ ë°°ì¹˜ ì‹¤í–‰ ê³µí†µ í•¨ìˆ˜
    
    Args:
        experiment_list: ì‹¤í—˜ ì¡°í•© ë¦¬ìŠ¤íŠ¸
        experiment_func: ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰ í•¨ìˆ˜
        experiment_type: ì‹¤í—˜ íƒ€ì… ("learning" ë˜ëŠ” "prediction")
        merged_df_clean: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        logger: ë¡œê±° ê°ì²´
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        **kwargs: experiment_funcì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
    
    Returns:
        ì‹¤í—˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    emoji_map = {"learning": "ğŸ“", "prediction": "ğŸ”®"}
    emoji = emoji_map.get(experiment_type, "ğŸ”¬")
    
    print("="*80)
    print(f"{emoji} {experiment_type.capitalize()} Experiments ì‹¤í–‰")
    print("="*80)
    
    total_experiments = len(experiment_list)
    print(f"\nğŸ“Š ì´ {total_experiments}ê°œì˜ {experiment_type} ì‹¤í—˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n")
    
    results = []
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # CSV ì„¤ì •
    csv_file = None
    csv_columns = None
    if output_dir:
        results_file = output_dir / f"{experiment_type}_results_{timestamp}.json"
        csv_file = output_dir / f"{experiment_type}_results_{timestamp}.csv"
        
        if experiment_type == "learning":
            csv_columns = [
                'graph_name', 'treatment', 'estimator', 'ate_value',
                'placebo_passed', 'placebo_pvalue',
                'unobserved_passed', 'unobserved_pvalue',
                'subset_passed', 'subset_pvalue',
                'dummy_passed', 'dummy_pvalue',
                'f1_score', 'auc', 'duration_seconds'
            ]
        else:  # prediction
            csv_columns = [
                'graph_name', 'treatment', 'estimator', 'f1_score', 'auc', 'accuracy'
            ]
        
        pd.DataFrame(columns=csv_columns).to_csv(csv_file, index=False, encoding='utf-8-sig')
    
    # ì‹¤í—˜ ì‹¤í–‰
    for idx, (graph_file, treatment, outcome, estimator) in enumerate(experiment_list, 1):
        experiment_id = f"exp_{idx:04d}_{Path(graph_file).stem}_{treatment}_{outcome}_{estimator}"
        
        print(f"\n[{idx}/{total_experiments}] {experiment_type.capitalize()} ì‹¤í–‰ ì¤‘...")
        
        # ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰
        result = experiment_func(
            merged_df_clean=merged_df_clean,
            graph_file=graph_file,
            treatment=treatment,
            outcome=outcome,
            estimator=estimator,
            experiment_id=experiment_id,
            logger=logger,
            **kwargs
        )
        
        results.append(result)
        
        # CSVì— ê²°ê³¼ ì¶”ê°€
        if output_dir and csv_file and result.get("status") == "success":
            if experiment_type == "learning":
                csv_row = {
                    'graph_name': result.get('graph_name', ''),
                    'treatment': result.get('treatment', ''),
                    'estimator': result.get('estimator', ''),
                    'ate_value': result.get('ate_value'),
                    'placebo_passed': result.get('placebo_passed'),
                    'placebo_pvalue': result.get('placebo_pvalue'),
                    'unobserved_passed': result.get('unobserved_passed'),
                    'unobserved_pvalue': result.get('unobserved_pvalue'),
                    'subset_passed': result.get('subset_passed'),
                    'subset_pvalue': result.get('subset_pvalue'),
                    'dummy_passed': result.get('dummy_passed'),
                    'dummy_pvalue': result.get('dummy_pvalue'),
                    'f1_score': result.get('f1_score'),
                    'auc': result.get('auc'),
                    'duration_seconds': result.get('duration_seconds')
                }
            else:  # prediction
                metrics = result.get("metrics", {})
                csv_row = {
                    'graph_name': result.get('graph_name', ''),
                    'treatment': result.get('treatment', ''),
                    'estimator': result.get('estimator', ''),
                    'f1_score': metrics.get('f1_score'),
                    'auc': metrics.get('auc'),
                    'accuracy': metrics.get('accuracy')
                }
            
            _save_result_to_csv(csv_file, csv_columns, csv_row)
        
        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (JSON)
        if output_dir:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
        
        success_count = sum(1 for r in results if r.get("status") == "success")
        failed_count = sum(1 for r in results if r.get("status") == "failed")
        print(f"\nâœ… ì„±ê³µ: {success_count}, âŒ ì‹¤íŒ¨: {failed_count}")
    
    # ìµœì¢… ìš”ì•½
    print(f"\n{'='*80}")
    print(f"ğŸ“‹ {experiment_type.capitalize()} Experiments ì™„ë£Œ")
    print(f"{'='*80}")
    print(f"ì´ ì‹¤í—˜ ìˆ˜: {total_experiments}")
    success_count = sum(1 for r in results if r.get("status") == "success")
    failed_count = sum(1 for r in results if r.get("status") == "failed")
    print(f"ì„±ê³µ: {success_count}")
    print(f"ì‹¤íŒ¨: {failed_count}")
    if output_dir:
        print(f"JSON ê²°ê³¼ íŒŒì¼: {results_file}")
        print(f"CSV ê²°ê³¼ íŒŒì¼: {csv_file}")
    print(f"{'='*80}\n")
    
    return results


def learning_experiments(
    merged_df_clean: pd.DataFrame,
    experiment_list: List[Tuple[str, str, str, str]],
    logger: Optional[Any] = None,
    output_dir: Optional[Path] = None
) -> List[Dict[str, Any]]:
    """
    experiment_listì˜ ëª¨ë“  ì¡°í•©ì— ëŒ€í•´ learning ì‹¤í–‰
    
    Args:
        merged_df_clean: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        experiment_list: ì‹¤í—˜ ì¡°í•© ë¦¬ìŠ¤íŠ¸ [(graph_file, treatment, outcome, estimator), ...]
        logger: ë¡œê±° ê°ì²´ (ì„ íƒì )
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì„ íƒì )
    
    Returns:
        ì‹¤í—˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    return _run_experiments_batch(
        experiment_list=experiment_list,
        experiment_func=learning,
        experiment_type="learning",
        merged_df_clean=merged_df_clean,
        logger=logger,
        output_dir=output_dir
    )


def prediction(
    merged_df_clean: pd.DataFrame,
    graph_file: str,
    treatment: str,
    outcome: str,
    estimator: str,
    checkpoint_dir: Path,
    experiment_id: Optional[str] = None,
    logger: Optional[Any] = None
) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ì‹¤í—˜ì— ëŒ€í•œ prediction í•¨ìˆ˜
    ë‹¨ì¼ ê·¸ë˜í”„, íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ ë° í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ prediction ì§„í–‰ ë° ê²°ê³¼ ì§€í‘œ ì¶œë ¥
    
    Args:
        merged_df_clean: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        graph_file: ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
        treatment: íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ ë³€ìˆ˜ëª…
        outcome: ê²°ê³¼ ë³€ìˆ˜ëª…
        estimator: ì¶”ì • ë°©ë²•
        checkpoint_dir: checkpoint ë””ë ‰í† ë¦¬ ê²½ë¡œ
        experiment_id: ì‹¤í—˜ ID (ì„ íƒì )
        logger: ë¡œê±° ê°ì²´ (ì„ íƒì )
    
    Returns:
        ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if experiment_id is None:
        experiment_id = f"{Path(graph_file).stem}_{treatment}_{outcome}_{estimator}"
    
    print(f"\n{'='*80}")
    print(f"ğŸ”® Prediction ì‹¤í–‰ - {experiment_id}")
    print(f"ê·¸ë˜í”„: {Path(graph_file).name}")
    print(f"Treatment: {treatment}, Outcome: {outcome}, Estimator: {estimator}")
    print(f"{'='*80}\n")
    
    try:
        result = run_inference(
            merged_df_clean=merged_df_clean,
            graph_file=graph_file,
            checkpoint_dir=checkpoint_dir,
            treatment=treatment,
            outcome=outcome,
            estimator=estimator,
            logger=logger,
            experiment_id=experiment_id
        )
        
        result["experiment_id"] = experiment_id
        result["graph_name"] = Path(graph_file).stem
        result["treatment"] = treatment
        result["outcome"] = outcome
        result["estimator"] = estimator
        
        if result.get("status") == "success":
            metrics = result.get("metrics", {})
            print(f"âœ… Prediction ì™„ë£Œ: {experiment_id}")
            print(f"   Accuracy: {metrics.get('accuracy', 'N/A')}")
            print(f"   F1 Score: {metrics.get('f1_score', 'N/A')}")
            print(f"   AUC: {metrics.get('auc', 'N/A')}")
        else:
            print(f"âŒ Prediction ì‹¤íŒ¨: {experiment_id}")
            if result.get("error"):
                print(f"   ì—ëŸ¬: {result['error']}")
        
        return result
        
    except Exception as e:
        print(f"âŒ Prediction ì‹¤íŒ¨: {experiment_id}")
        print(f"   ì—ëŸ¬: {e}")
        return {
            "status": "failed",
            "experiment_id": experiment_id,
            "error": str(e)
        }


def prediction_experiments(
    merged_df_clean: pd.DataFrame,
    experiment_list: List[Tuple[str, str, str, str]],
    checkpoint_dir: Path,
    logger: Optional[Any] = None,
    output_dir: Optional[Path] = None
) -> List[Dict[str, Any]]:
    """
    experiment_listì˜ ëª¨ë“  ì¡°í•©ì— ëŒ€í•´ prediction ì‹¤í–‰ ë° ê²°ê³¼ ì§€í‘œë¥¼ CSVë¡œ ì €ì¥
    
    Args:
        merged_df_clean: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        experiment_list: ì‹¤í—˜ ì¡°í•© ë¦¬ìŠ¤íŠ¸ [(graph_file, treatment, outcome, estimator), ...]
        checkpoint_dir: checkpoint ë””ë ‰í† ë¦¬ ê²½ë¡œ
        logger: ë¡œê±° ê°ì²´ (ì„ íƒì )
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì„ íƒì )
    
    Returns:
        ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    return _run_experiments_batch(
        experiment_list=experiment_list,
        experiment_func=prediction,
        experiment_type="prediction",
        merged_df_clean=merged_df_clean,
        logger=logger,
        output_dir=output_dir,
        checkpoint_dir=checkpoint_dir
    )


def _get_graph_files(
    config: Dict[str, Any],
    data_dir_path: Path,
    graph_data_dir: str
) -> List[str]:
    """
    ì„¤ì •ì— ë”°ë¼ ê·¸ë˜í”„ íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜
    
    Args:
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        data_dir_path: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        graph_data_dir: ê·¸ë˜í”„ ë°ì´í„° ë””ë ‰í† ë¦¬ëª…
    
    Returns:
        ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    graphs = config.get("graphs", [])
    auto_extract_treatments = config.get("auto_extract_treatments", False)
    
    if auto_extract_treatments:
        found_graphs = find_all_graph_files(data_dir_path, graph_data_dir)
        return [str(g) for g in found_graphs]
    
    graph_files = []
    for graph in graphs:
        if isinstance(graph, str):
            graph_path = data_dir_path / graph_data_dir / graph
            if graph_path.exists():
                graph_files.append(str(graph_path))
            else:
                graph_path = Path(graph)
                if graph_path.exists():
                    graph_files.append(str(graph_path))
    
    return graph_files


def _extract_treatments_from_graphs(
    graph_files: List[str],
    auto_extract: bool
) -> Tuple[Dict[str, List[str]], Dict[str, str]]:
    """
    ê·¸ë˜í”„ íŒŒì¼ë“¤ì—ì„œ treatmentì™€ outcomeì„ ì¶”ì¶œí•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜
    
    Args:
        graph_files: ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        auto_extract: ìë™ ì¶”ì¶œ ì—¬ë¶€
    
    Returns:
        (graph_treatments_map, graph_outcomes_map) íŠœí”Œ
    """
    graph_treatments_map = {}
    graph_outcomes_map = {}
    
    if auto_extract:
        for graph_file in graph_files:
            graph_path = Path(graph_file)
            extracted_treatments = extract_treatments_from_graph(graph_path)
            
            if extracted_treatments:
                graph_treatments_map[graph_file] = [
                    t["treatment_var"] for t in extracted_treatments 
                    if t.get("treatment_var")
                ]
                if extracted_treatments[0].get("outcome"):
                    graph_outcomes_map[graph_file] = extracted_treatments[0]["outcome"]
    
    return graph_treatments_map, graph_outcomes_map


def _sort_estimators(estimators: List[str]) -> List[str]:
    """
    estimator ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜ (linear_regression, tabpfn ìš°ì„ )
    
    Args:
        estimators: estimator ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ì •ë ¬ëœ estimator ë¦¬ìŠ¤íŠ¸
    """
    sorted_estimators = []
    priority_estimators = ["linear_regression", "tabpfn"]
    
    for est in priority_estimators:
        if est in estimators:
            sorted_estimators.append(est)
    
    for est in estimators:
        if est not in sorted_estimators:
            sorted_estimators.append(est)
    
    return sorted_estimators


def create_experiment_list(
    config: Dict[str, Any],
    data_dir_path: Path,
    graph_data_dir: str
) -> List[Tuple[str, str, str, str]]:
    """
    config.jsonì—ì„œ experiment_listë¥¼ ì½ì–´ì„œ ì‹¤í—˜ ì¡°í•© ë¦¬ìŠ¤íŠ¸ ìƒì„±
    
    Args:
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        data_dir_path: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        graph_data_dir: ê·¸ë˜í”„ ë°ì´í„° ë””ë ‰í† ë¦¬ëª…
    
    Returns:
        ì‹¤í—˜ ì¡°í•© ë¦¬ìŠ¤íŠ¸ [(graph_file, treatment, outcome, estimator), ...]
    """
    # config.jsonì— experiment_listê°€ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    experiment_list_config = config.get("experiment_list", [])
    
    if experiment_list_config:
        # config.jsonì—ì„œ ì§ì ‘ ì •ì˜ëœ experiment_list ì‚¬ìš©
        experiment_combinations = []
        graph_data_path = data_dir_path / graph_data_dir
        
        for exp in experiment_list_config:
            if isinstance(exp, list) and len(exp) >= 4:
                # ë°°ì—´ í˜•ì‹: ["graph_1.dot", "BFR_OCTR_CT", "ACQ_180_YN", "tabpfn"]
                graph_name, treatment, outcome, estimator = exp[0], exp[1], exp[2], exp[3]
            elif isinstance(exp, dict):
                # ë”•ì…”ë„ˆë¦¬ í˜•ì‹: {"graph": "graph_1.dot", "treatment": "BFR_OCTR_CT", ...}
                graph_name = exp.get("graph", "")
                treatment = exp.get("treatment", "")
                outcome = exp.get("outcome", "ACQ_180_YN")
                estimator = exp.get("estimator", "tabpfn")
            else:
                print(f"âš ï¸ ì˜ëª»ëœ experiment_list í˜•ì‹: {exp}")
                continue
            
            # ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ í™•ì¸
            graph_path = graph_data_path / graph_name
            if not graph_path.exists():
                # ì ˆëŒ€ ê²½ë¡œë¡œ ì‹œë„
                graph_path = Path(graph_name)
                if not graph_path.exists():
                    print(f"âš ï¸ ê·¸ë˜í”„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {graph_name}")
                    continue
            
            experiment_combinations.append(
                (str(graph_path), treatment, outcome, estimator)
            )
        
        return experiment_combinations
    
    # ê¸°ì¡´ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜ì„±)
    treatments = config.get("treatments", [])
    outcomes = config.get("outcomes", ["ACQ_180_YN"])
    estimators = config.get("estimators", ["tabpfn"])
    auto_extract_treatments = config.get("auto_extract_treatments", False)
    
    # ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
    graph_files = _get_graph_files(config, data_dir_path, graph_data_dir)
    
    if not graph_files:
        return []
    
    # treatment ìë™ ì¶”ì¶œ
    graph_treatments_map, graph_outcomes_map = _extract_treatments_from_graphs(
        graph_files, auto_extract_treatments
    )
    
    # estimator ì •ë ¬
    sorted_estimators = _sort_estimators(estimators)
    
    # ì‹¤í—˜ ì¡°í•© ìƒì„±
    if auto_extract_treatments and graph_treatments_map:
        experiment_combinations = []
        for graph_file in graph_files:
            graph_treatments = graph_treatments_map.get(graph_file, treatments)
            graph_outcome = graph_outcomes_map.get(
                graph_file, 
                outcomes[0] if outcomes else "ACQ_180_YN"
            )
            
            for treatment in graph_treatments:
                for estimator in sorted_estimators:
                    experiment_combinations.append(
                        (graph_file, treatment, graph_outcome, estimator)
                    )
    else:
        experiment_combinations = list(itertools.product(
            graph_files,
            treatments,
            outcomes,
            sorted_estimators
        ))
    
    return experiment_combinations


def prepare_data_for_causal_model(
    merged_df: pd.DataFrame,
    config: Dict[str, Any],
    data_dir_path: Path,
    graph_data_dir: str
) -> pd.DataFrame:
    """
    ì¸ê³¼ ëª¨ë¸ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ (ê·¸ë˜í”„ ë³€ìˆ˜ì— ë§ê²Œ ë°ì´í„° ì •ë¦¬)
    
    Args:
        merged_df: ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        data_dir_path: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        graph_data_dir: ê·¸ë˜í”„ ë°ì´í„° ë””ë ‰í† ë¦¬ëª…
    
    Returns:
        ì •ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
    """
    treatments = config.get("treatments", [])
    outcomes = config.get("outcomes", ["ACQ_180_YN"])
    auto_extract_treatments = config.get("auto_extract_treatments", False)
    
    # ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬ (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
    graph_files = _get_graph_files(config, data_dir_path, graph_data_dir)
    
    if not graph_files:
        return merged_df
    
    # ëª¨ë“  ê·¸ë˜í”„ì˜ ë³€ìˆ˜ ìˆ˜ì§‘
    all_graph_variables = set()
    for graph_file in graph_files:
        graph_path = Path(graph_file)
        try:
            causal_graph = create_causal_graph(str(graph_path))
            all_graph_variables.update(causal_graph.nodes())
        except Exception as e:
            print(f"âš ï¸ ê·¸ë˜í”„ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({graph_path.name}): {e}")
    
    # treatment ìë™ ì¶”ì¶œ (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
    graph_treatments_map, graph_outcomes_map = _extract_treatments_from_graphs(
        graph_files, auto_extract_treatments
    )
    
    # ë°ì´í„° ì •ë¦¬
    all_treatments = set()
    all_outcomes = set()
    for graph_file in graph_files:
        if graph_file in graph_treatments_map:
            all_treatments.update(graph_treatments_map[graph_file])
        if graph_file in graph_outcomes_map:
            all_outcomes.add(graph_outcomes_map[graph_file])
    if not auto_extract_treatments:
        all_treatments.update(treatments)
    if not graph_outcomes_map:
        all_outcomes.update(outcomes)
    
    essential_vars = all_treatments | all_outcomes | {"SEEK_CUST_NO", "JHNT_CTN", "JHNT_MBN"}
    stratification_vars = {"HOPE_JSCD3_NAME"}
    required_vars = list(all_graph_variables | essential_vars | stratification_vars)
    
    merged_df_clean = clean_dataframe_for_causal_model(
        merged_df, 
        required_vars=required_vars, 
        logger=None
    )
    
    data_variables = set(merged_df_clean.columns)
    vars_to_keep = (all_graph_variables | essential_vars | stratification_vars) & data_variables
    vars_to_remove = data_variables - vars_to_keep
    
    if vars_to_remove:
        print(f"ğŸ—‘ï¸ ê·¸ë˜í”„ì— ì •ì˜ë˜ì§€ ì•Šì€ ë³€ìˆ˜ ì œê±° ì¤‘ ({len(vars_to_remove)}ê°œ)...")
        merged_df_clean = merged_df_clean[list(vars_to_keep)]
    
    print(f"âœ… ì •ë¦¬ëœ ë°ì´í„°: {len(merged_df_clean)}ê±´, {len(merged_df_clean.columns)}ê°œ ë³€ìˆ˜")
    
    return merged_df_clean


def main():
    parser = argparse.ArgumentParser(description="LaborLab 2 ì¸ê³¼ì¶”ë¡  ë¶„ì„ íŒŒì´í”„ë¼ì¸")
    parser.add_argument("--config", type=str, default="config.json", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    script_dir = Path(__file__).parent.parent
    
    if os.path.isabs(args.config):
        config_path = Path(args.config)
    else:
        config_path = script_dir / args.config
    
    if not config_path.exists():
        print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.config}")
        print(f"   í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")
        print(f"   ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬: {script_dir}")
        return
    
    print(f"ğŸ“„ ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
    config = load_config(config_path)
    
    # ì„¤ì • ê°’ ì¶”ì¶œ
    data_dir = config.get("data_dir", "data")
    seis_data_dir = config.get("seis_data_dir", "seis_data")
    graph_data_dir = config.get("graph_data_dir", "graph_data")
    output_dir = config.get("output_dir", "log")
    limit_data = config.get("limit_data", False)
    limit_size = config.get("limit_size", 5000)
    checkpoint_dir = config.get("checkpoint_dir", "data/checkpoint")
    job_category_file = config.get("job_category_file", "KSIC")
    
    # ìƒˆë¡œìš´ ì„¤ì • ë³€ìˆ˜
    do_preprocess = config.get("preprocess", True)
    do_learning = config.get("learning", False)
    do_prediction = config.get("prediction", False)
    do_experiment = config.get("experiment", False)
    
    # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    data_dir_path = script_dir / data_dir
    output_dir_path = script_dir / output_dir
    output_dir_path.mkdir(exist_ok=True)
    checkpoint_dir_path = script_dir / checkpoint_dir
    checkpoint_dir_path.mkdir(parents=True, exist_ok=True)
    
    # ë¡œê±° ì„¤ì •
    logger = None
    if not config.get("no_logs", False):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        logger = setup_logging(
            log_dir=output_dir_path,
            log_filename=f"pipeline_{timestamp}.log"
        )
        if logger:
            logger.info(f"íŒŒì´í”„ë¼ì¸ ì‹œì‘ - {timestamp}")
    
    merged_df = None
    merged_df_clean = None
    experiment_list = []
    
    # ========================================================================
    # 1. ì „ì²˜ë¦¬ ì‹¤í–‰
    # ========================================================================
    if do_preprocess:
        merged_df = preprocess(
            data_dir_path=data_dir_path,
            seis_data_dir=seis_data_dir,
            limit_data=limit_data,
            limit_size=limit_size,
            job_category_file=job_category_file
        )
        
        # ì¸ê³¼ ëª¨ë¸ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
        merged_df_clean = prepare_data_for_causal_model(
            merged_df=merged_df,
            config=config,
            data_dir_path=data_dir_path,
            graph_data_dir=graph_data_dir
        )
    
    # ========================================================================
    # 2. experiment_list ìƒì„±
    # ========================================================================
    if do_experiment or do_learning or do_prediction:
        experiment_list = create_experiment_list(
            config=config,
            data_dir_path=data_dir_path,
            graph_data_dir=graph_data_dir
        )
        
        if not experiment_list:
            print("âŒ ìœ íš¨í•œ ì‹¤í—˜ ì¡°í•©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“Š ìƒì„±ëœ ì‹¤í—˜ ì¡°í•©: {len(experiment_list)}ê°œ\n")
    
    # ========================================================================
    # 3. Learning ì‹¤í–‰
    # ========================================================================
    if do_learning:
        if merged_df_clean is None:
            print("âŒ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. preprocessë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        if do_experiment:
            # experiment_listì˜ ëª¨ë“  ì¡°í•©ì— ëŒ€í•´ learning ì‹¤í–‰
            learning_experiments(
                merged_df_clean=merged_df_clean,
                experiment_list=experiment_list,
                logger=logger,
                output_dir=output_dir_path
            )
        else:
            # ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰ (configì—ì„œ ì²« ë²ˆì§¸ ì‹¤í—˜ ì¡°í•© ì‚¬ìš©)
            if experiment_list:
                graph_file, treatment, outcome, estimator = experiment_list[0]
                learning(
                    merged_df_clean=merged_df_clean,
                    graph_file=graph_file,
                    treatment=treatment,
                    outcome=outcome,
                    estimator=estimator,
                    logger=logger
                )
            else:
                print("âŒ ì‹¤í–‰í•  ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ========================================================================
    # 4. Prediction ì‹¤í–‰
    # ========================================================================
    if do_prediction:
        if merged_df_clean is None:
            print("âŒ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. preprocessë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        if do_experiment:
            # experiment_listì˜ ëª¨ë“  ì¡°í•©ì— ëŒ€í•´ prediction ì‹¤í–‰
            prediction_experiments(
                merged_df_clean=merged_df_clean,
                experiment_list=experiment_list,
                checkpoint_dir=checkpoint_dir_path,
                logger=logger,
                output_dir=output_dir_path
            )
        else:
            # ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰ (configì—ì„œ ì²« ë²ˆì§¸ ì‹¤í—˜ ì¡°í•© ì‚¬ìš©)
            if experiment_list:
                graph_file, treatment, outcome, estimator = experiment_list[0]
                prediction(
                    merged_df_clean=merged_df_clean,
                    graph_file=graph_file,
                    treatment=treatment,
                    outcome=outcome,
                    estimator=estimator,
                    checkpoint_dir=checkpoint_dir_path,
                    logger=logger
                )
            else:
                print("âŒ ì‹¤í–‰í•  ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"\n{'='*80}")
    print("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()
