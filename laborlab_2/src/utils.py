"""
ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ - ê·¸ë˜í”„ íŒŒì‹±, ë°ì´í„° ë¡œë“œ, ì „ì²˜ë¦¬, ë¡œê¹… ê¸°ëŠ¥
"""
import re
import logging
import os
import json
import time
import itertools
import pandas as pd
import numpy as np
import networkx as nx
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from sklearn.model_selection import train_test_split

# DoWhy ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from dowhy import CausalModel


# ============================================================================
# ê·¸ë˜í”„ íŒŒì‹± í•¨ìˆ˜
# ============================================================================

def extract_treatments_from_dot(dot_file_path: Path) -> List[Dict[str, str]]:
    """
    .dot íŒŒì¼ì—ì„œ treatment ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Input:
        dot_file_path (Path): .dot íŒŒì¼ ê²½ë¡œ
    
    Output:
        List[Dict[str, str]]: treatment ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ê° treatmentëŠ” dict í˜•íƒœ)
            - ê° dictëŠ” ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨: node, treatment_var, treatment_name, 
              treatment_def, treatment_question, label, outcome
    """
    with open(dot_file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    treatments = []
    
    # subgraph cluster_treatments ë¸”ë¡ ì°¾ê¸°
    subgraph_pattern = r'subgraph\s+cluster_treatments\s*\{[^}]*\}'
    subgraph_match = re.search(subgraph_pattern, content, re.DOTALL)
    
    if not subgraph_match:
        return treatments
    
    subgraph_content = subgraph_match.group(0)
    
    # T1, T2, ... í˜•íƒœì˜ treatment ë…¸ë“œ ì°¾ê¸°
    treatment_pattern = r'(T\d+)\s*\[([^\]]+)\]'
    treatment_matches = re.finditer(treatment_pattern, subgraph_content, re.DOTALL)
    
    for match in treatment_matches:
        node_name = match.group(1)  # T1, T2, etc.
        node_attrs = match.group(2)
        
        # ì†ì„± ì¶”ì¶œ
        treatment_var = re.search(r'treatment_var\s*=\s*"([^"]+)"', node_attrs)
        treatment_name = re.search(r'treatment_name\s*=\s*"([^"]+)"', node_attrs)
        treatment_def = re.search(r'treatment_def\s*=\s*"([^"]+)"', node_attrs)
        treatment_question = re.search(r'treatment_question\s*=\s*"([^"]+)"', node_attrs)
        label = re.search(r'label\s*=\s*"([^"]+)"', node_attrs)
        
        treatment_info = {
            "node": node_name,
            "treatment_var": treatment_var.group(1) if treatment_var else "",
            "treatment_name": treatment_name.group(1) if treatment_name else "",
            "treatment_def": treatment_def.group(1) if treatment_def else "",
            "treatment_question": treatment_question.group(1) if treatment_question else "",
            "label": label.group(1) if label else node_name,
        }
        
        # outcome ì •ë³´ë„ ì¶”ì¶œ (subgraphì˜ labelì—ì„œ)
        outcome_match = re.search(r'label\s*=\s*"Treatments\s*\(outcome:\s*([^)]+)\)"', subgraph_content)
        if outcome_match:
            treatment_info["outcome"] = outcome_match.group(1).strip()
        
        treatments.append(treatment_info)
    
    return treatments


def extract_treatments_from_gml(gml_file_path: Path) -> List[Dict[str, str]]:
    """
    GML í˜•ì‹ íŒŒì¼ì—ì„œ treatment ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Input:
        gml_file_path (Path): GML íŒŒì¼ ê²½ë¡œ
    
    Output:
        List[Dict[str, str]]: treatment ì •ë³´ ë¦¬ìŠ¤íŠ¸ (í˜„ì¬ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
    """
    # GML í˜•ì‹ì€ í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ, í™•ì¥ì„±ì„ ìœ„í•´ í•¨ìˆ˜ ì •ì˜
    # í•„ìš”ì‹œ êµ¬í˜„
    return []


def extract_treatments_from_graph(graph_file_path: Path) -> List[Dict[str, str]]:
    """
    ê·¸ë˜í”„ íŒŒì¼ì—ì„œ treatment ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ íŒŒì„œë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    
    Input:
        graph_file_path (Path): ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
    
    Output:
        List[Dict[str, str]]: treatment ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    graph_path = Path(graph_file_path)
    
    if graph_path.suffix == '.dot':
        return extract_treatments_from_dot(graph_path)
    elif graph_path.suffix == '' or 'graph' in graph_path.name:
        # GML í˜•ì‹ íŒŒì¼ (í™•ì¥ì ì—†ìŒ)
        return extract_treatments_from_gml(graph_path)
    else:
        return []


def find_all_graph_files(data_dir: Path, graph_data_dir: Optional[str] = None) -> List[Path]:
    """
    ë°ì´í„° ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  ê·¸ë˜í”„ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    Input:
        data_dir (Path): ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        graph_data_dir (Optional[str]): ê·¸ë˜í”„ ë°ì´í„° ë””ë ‰í† ë¦¬ ì´ë¦„ (ê¸°ë³¸ê°’: "graph_data")
    
    Output:
        List[Path]: ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ì •ë ¬ëœ ìˆœì„œ)
    """
    if graph_data_dir is None:
        graph_data_dir = "graph_data"
    
    graph_data_path = Path(data_dir) / graph_data_dir
    
    if not graph_data_path.exists():
        return []
    
    # .dot íŒŒì¼ê³¼ í™•ì¥ì ì—†ëŠ” graph íŒŒì¼ ì°¾ê¸°
    graph_files = []
    
    # .dot íŒŒì¼
    graph_files.extend(graph_data_path.glob("graph_*.dot"))
    
    # í™•ì¥ì ì—†ëŠ” graph íŒŒì¼ (GML í˜•ì‹)
    for graph_file in graph_data_path.glob("graph_*"):
        if not graph_file.suffix and graph_file.is_file():
            graph_files.append(graph_file)
    
    # ì •ë ¬í•˜ì—¬ ë°˜í™˜
    return sorted(graph_files)


def get_treatments_from_all_graphs(data_dir: Path, graph_data_dir: Optional[str] = None) -> Dict[str, List[Dict[str, str]]]:
    """
    ëª¨ë“  ê·¸ë˜í”„ íŒŒì¼ì—ì„œ treatment ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Input:
        data_dir (Path): ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        graph_data_dir (Optional[str]): ê·¸ë˜í”„ ë°ì´í„° ë””ë ‰í† ë¦¬ ì´ë¦„
    
    Output:
        Dict[str, List[Dict[str, str]]]: {graph_file_name: [treatment_info, ...]} ë”•ì…”ë„ˆë¦¬
    """
    graph_files = find_all_graph_files(data_dir, graph_data_dir)
    
    result = {}
    
    for graph_file in graph_files:
        treatments = extract_treatments_from_graph(graph_file)
        if treatments:
            result[str(graph_file)] = treatments
    
    return result


# ============================================================================
# ë¡œê¹… í•¨ìˆ˜
# ============================================================================

def setup_logging(
    log_dir: Optional[Path] = None,
    log_filename: Optional[str] = None,
    level: int = logging.INFO,
    no_logs: bool = False
) -> Optional[logging.Logger]:
    """
    ë¡œê¹…ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
    
    Input:
        log_dir (Optional[Path]): ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        log_filename (Optional[str]): ë¡œê·¸ íŒŒì¼ëª… (Noneì´ë©´ ìë™ ìƒì„±)
        level (int): ë¡œê¹… ë ˆë²¨ (ê¸°ë³¸ê°’: logging.INFO)
        no_logs (bool): ë¡œê·¸ ì €ì¥ ë¹„í™œì„±í™” ì—¬ë¶€
    
    Output:
        Optional[logging.Logger]: Logger ê°ì²´ ë˜ëŠ” None (no_logs=Trueì¸ ê²½ìš°)
    """
    if no_logs:
        return None
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì •
    if log_dir is None:
        script_dir = Path(__file__).parent.parent
        log_dir = script_dir / "log"
    else:
        log_dir = Path(log_dir)
    
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¡œê·¸ íŒŒì¼ëª… ì„¤ì •
    if log_filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_filename = f"experiment_{timestamp}.log"
    
    log_filepath = log_dir / log_filename
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filepath, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"ë¡œê¹… ì‹œì‘ - ë¡œê·¸ íŒŒì¼: {log_filepath}")
    
    return logger


# ============================================================================
# ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜
# ============================================================================

def create_causal_graph(graph_file: str) -> nx.DiGraph:
    """
    DOT í˜•ì‹ ê·¸ë˜í”„ íŒŒì¼ì„ ì½ì–´ì„œ NetworkX ì¸ê³¼ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Input:
        graph_file (str): ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ (DOT í˜•ì‹)
    
    Output:
        nx.DiGraph: ì¸ê³¼ ê·¸ë˜í”„ ê°ì²´ (NetworkX ë°©í–¥ì„± ê·¸ë˜í”„)
    """
    return _parse_dot_graph(graph_file)


def _parse_dot_graph(graph_file: str) -> nx.DiGraph:
    """
    DOT í˜•ì‹ ê·¸ë˜í”„ íŒŒì¼ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    
    Input:
        graph_file (str): ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
    
    Output:
        nx.DiGraph: íŒŒì‹±ëœ NetworkX ë°©í–¥ì„± ê·¸ë˜í”„
    """
    try:
        # pydotì„ ì‚¬ìš©í•˜ì—¬ DOT íŒŒì¼ ì½ê¸°
        import pydot
        graphs = pydot.graph_from_dot_file(graph_file)
        if not graphs:
            raise ValueError(f"DOT íŒŒì¼ì—ì„œ ê·¸ë˜í”„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {graph_file}")
        
        # ì²« ë²ˆì§¸ ê·¸ë˜í”„ ì‚¬ìš©
        dot_graph = graphs[0]
        
        # NetworkX ê·¸ë˜í”„ë¡œ ë³€í™˜
        G = nx.drawing.nx_pydot.from_pydot(dot_graph)
        
        # ë°©í–¥ì„± ê·¸ë˜í”„ë¡œ ë³€í™˜ (digraphì¸ ê²½ìš°)
        if not G.is_directed():
            with open(graph_file, 'r', encoding='utf-8') as f:
                content = f.read()
            if content.strip().startswith('digraph'):
                G = G.to_directed()
        
        return G
    except ImportError:
        # pydotì´ ì—†ìœ¼ë©´ ìˆ˜ë™ íŒŒì‹±
        return _parse_dot_manual(graph_file)
    except Exception as e:
        # pydot íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ íŒŒì‹± ì‹œë„
        try:
            return _parse_dot_manual(graph_file)
        except Exception as e2:
            raise ValueError(f"DOT íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {e}. ìˆ˜ë™ íŒŒì‹±ë„ ì‹¤íŒ¨: {e2}")


def _parse_dot_manual(graph_file: str) -> nx.DiGraph:
    """
    DOT í˜•ì‹ì„ ìˆ˜ë™ìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤ (pydot ì—†ì´).
    
    Input:
        graph_file (str): ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
    
    Output:
        nx.DiGraph: íŒŒì‹±ëœ NetworkX ë°©í–¥ì„± ê·¸ë˜í”„
    """
    with open(graph_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    G = nx.DiGraph()
    
    # digraphì¸ì§€ í™•ì¸
    is_digraph = content.strip().startswith('digraph')
    
    # subgraph cluster_treatments ë¸”ë¡ ì œê±°
    content_without_subgraph = re.sub(
        r'subgraph\s+cluster_treatments\s*\{[^}]*\}',
        '',
        content,
        flags=re.DOTALL
    )
    
    # ë…¸ë“œ ì •ì˜ ì°¾ê¸°
    node_pattern = r'([A-Za-z_][A-Za-z0-9_]*)\s*\[[^\]]*label\s*=\s*"([^"]+)"'
    for match in re.finditer(node_pattern, content_without_subgraph):
        node_id = match.group(1)
        label = match.group(2)
        if not re.match(r'^T\d+$', node_id):
            G.add_node(node_id, label=label)
    
    # ì—£ì§€ ì°¾ê¸°
    edge_pattern = r'([A-Za-z_][A-Za-z0-9_]*)\s*->\s*([A-Za-z_][A-Za-z0-9_]*)'
    for match in re.finditer(edge_pattern, content_without_subgraph):
        source = match.group(1)
        target = match.group(2)
        if not re.match(r'^T\d+$', source) and not re.match(r'^T\d+$', target):
            G.add_edge(source, target)
    
    # ë°©í–¥ì„± ê·¸ë˜í”„ë¡œ ë³€í™˜
    if is_digraph and not G.is_directed():
        G = G.to_directed()
    
    return G


# ============================================================================
# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# ============================================================================

def load_all_data(data_dir: str, seis_data_dir: str, graph_file: Optional[str] = None) -> Tuple[List[str], nx.DiGraph]:
    """
    ì •í˜• ë°ì´í„°ì™€ ë¹„ì •í˜• ë°ì´í„°(JSON)ë¥¼ ëª¨ë‘ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    
    Input:
        data_dir (str): ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        seis_data_dir (str): seis_data ë””ë ‰í† ë¦¬ ì´ë¦„
        graph_file (Optional[str]): ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ìœ¼ë¡œ ì°¾ìŒ)
    
    Output:
        Tuple[List[str], nx.DiGraph]: (íŒŒì¼ê²½ë¡œ_ë¦¬ìŠ¤íŠ¸, ì¸ê³¼ê·¸ë˜í”„)
            - íŒŒì¼ê²½ë¡œ_ë¦¬ìŠ¤íŠ¸: [ì •í˜•ë°ì´í„°ê²½ë¡œ, ì´ë ¥ì„œê²½ë¡œ, ìê¸°ì†Œê°œì„œê²½ë¡œ, ì§ì—…í›ˆë ¨ê²½ë¡œ, ìê²©ì¦ê²½ë¡œ]
            - ì¸ê³¼ê·¸ë˜í”„: NetworkX ë°©í–¥ì„± ê·¸ë˜í”„ ê°ì²´
    """
    data_path = Path(data_dir)
    
    # 1. ì •í˜• ë°ì´í„° íŒŒì¼ ê²½ë¡œ í™•ì¸ (seis_data í´ë”ì—ì„œ)
    structured_data_path = data_path / seis_data_dir / "seis_data.csv"
    
    if not structured_data_path.exists():
        raise FileNotFoundError(f"ì •í˜• ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {structured_data_path}")
    
    print(f"âœ… ì •í˜• ë°ì´í„° íŒŒì¼ ê²½ë¡œ: {structured_data_path}")
    
    # 2. ë¹„ì •í˜• ë°ì´í„°(JSON) íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    seis_data_path = data_path / seis_data_dir
    file_list = []
    
    json_files = [
        ("resume.json", "ì´ë ¥ì„œ"),
        ("coverletters.json", "ìê¸°ì†Œê°œì„œ"),
        ("trainings.json", "ì§ì—…í›ˆë ¨"),
        ("licenses.json", "ìê²©ì¦")
    ]
    
    # ì •í˜• ë°ì´í„° íŒŒì¼ì„ ë¨¼ì € ì¶”ê°€
    file_list.append(str(structured_data_path))
    
    # JSON íŒŒì¼ ê²½ë¡œ ì¶”ê°€
    for filename, json_type in json_files:
        json_path = seis_data_path / filename
        if json_path.exists():
            file_list.append(str(json_path))
            print(f"âœ… {json_type} íŒŒì¼ ê²½ë¡œ ì¶”ê°€: {json_path}")
        else:
            print(f"âš ï¸ {json_type} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")
    
    # 3. ì¸ê³¼ ê·¸ë˜í”„ ë¡œë“œ (graph_fileì´ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ì²« ë²ˆì§¸ ê·¸ë˜í”„ ì‚¬ìš©)
    if graph_file is None:
        graph_data_path = data_path / "graph_data"
        if graph_data_path.exists():
            graph_files = list(graph_data_path.glob("graph_*.dot"))
            if graph_files:
                graph_file = sorted(graph_files)[0]
                print(f"âš ï¸ ê·¸ë˜í”„ íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šì•„ {graph_file.name}ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                raise FileNotFoundError(f"ê·¸ë˜í”„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {graph_data_path}")
        else:
            raise FileNotFoundError(f"ê·¸ë˜í”„ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {graph_data_path}")
    else:
        graph_file = Path(graph_file)
    
    if not graph_file.exists():
        raise FileNotFoundError(f"ê·¸ë˜í”„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {graph_file}")
    
    causal_graph = create_causal_graph(str(graph_file))
    print(f"âœ… ì¸ê³¼ ê·¸ë˜í”„ ë¡œë“œ ì™„ë£Œ: {causal_graph.number_of_nodes()}ê°œ ë…¸ë“œ, {causal_graph.number_of_edges()}ê°œ ì—£ì§€")
    
    return file_list, causal_graph


# ============================================================================
# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜
# ============================================================================

def clean_dataframe_for_causal_model(df: pd.DataFrame, required_vars: Optional[List[str]] = None, logger: Optional[logging.Logger] = None) -> pd.DataFrame:
    """
    CausalModel ìƒì„± ì „ì— ë°ì´í„°í”„ë ˆì„ì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
    Logger ê°ì²´ë‚˜ ë‹¤ë¥¸ ë¹„ë°ì´í„° íƒ€ì… ì»¬ëŸ¼ ì œê±°
    
    Input:
        df (pd.DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        required_vars (Optional[List[str]]): ë°˜ë“œì‹œ ìœ ì§€í•´ì•¼ í•  ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ (treatment, outcome ë“±)
        logger (Optional[logging.Logger]): ë¡œê±° ê°ì²´
    
    Output:
        pd.DataFrame: ì •ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ (Logger ê°ì²´ ë“±ì´ ì œê±°ë¨)
    """
    df_clean = df.copy()
    cols_to_drop = []
    
    if required_vars is None:
        required_vars = []
    
    for col in df_clean.columns:
        if df_clean[col].dtype == 'object':
            if len(df_clean) > 0:
                non_null_values = df_clean[col].dropna()
                if len(non_null_values) > 0:
                    first_val = non_null_values.iloc[0]
                    is_logger_object = isinstance(first_val, logging.Logger) or 'Logger' in str(type(first_val))
                    is_invalid_type = not isinstance(first_val, (str, int, float, bool, type(None)))
                    
                    if is_logger_object or is_invalid_type:
                        if col in required_vars:
                            if logger:
                                logger.warning(f"í•„ìˆ˜ ë³€ìˆ˜ '{col}'ì˜ ê°’ì´ ê°ì²´ íƒ€ì…({type(first_val).__name__})ì´ì–´ì„œ NaNìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                            else:
                                print(f"âš ï¸ í•„ìˆ˜ ë³€ìˆ˜ '{col}'ì˜ ê°’ì´ ê°ì²´ íƒ€ì…({type(first_val).__name__})ì´ì–´ì„œ NaNìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                            df_clean[col] = np.nan
                        else:
                            cols_to_drop.append(col)
    
    if cols_to_drop:
        df_clean = df_clean.drop(columns=cols_to_drop)
    
    return df_clean


def preprocess_and_merge_data(file_list: List[str], data_dir: str, limit_data: bool = False, limit_size: int = 5000, job_category_file: str = "KSIC") -> pd.DataFrame:
    """
    Preprocessor í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê³  ë³‘í•©í•˜ëŠ” í•¨ìˆ˜
    
    Input:
        file_list (List[str]): íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ [ì •í˜•ë°ì´í„°, ì´ë ¥ì„œ, ìê¸°ì†Œê°œì„œ, ì§ì—…í›ˆë ¨, ìê²©ì¦]
        data_dir (str): ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        limit_data (bool): í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ë°ì´í„° ì œí•œ ì—¬ë¶€
        limit_size (int): ì œí•œí•  ë°ì´í„° í¬ê¸°
        job_category_file (str): ì§ì¢… ì†Œë¶„ë¥˜ íŒŒì¼ëª… (KECO, KSCO, KSIC ì¤‘ ì„ íƒ, ê¸°ë³¸ê°’: KSIC)
    
    Output:
        pd.DataFrame: ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„
    """
    from . import preprocess
    preprocessor = preprocess.Preprocessor([], job_category_file=job_category_file)
    absolute_file_list = [str(Path(f).resolve()) for f in file_list]
    merged_df = preprocessor.get_merged_df(absolute_file_list, limit_data=limit_data, limit_size=limit_size)
    print(f"âœ… ëª¨ë“  ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³‘í•© ì™„ë£Œ")
    return merged_df


# ============================================================================
# ê²°ê³¼ ì €ì¥ í•¨ìˆ˜
# ============================================================================

def save_predictions_to_excel(df_with_predictions: pd.DataFrame, output_dir: Optional[Path] = None, filename: Optional[str] = None, logger: Optional[logging.Logger] = None) -> str:
    """
    ì˜ˆì¸¡ê°’ì´ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ì„ Excel íŒŒì¼ë¡œ ì €ì¥
    
    Input:
        df_with_predictions (pd.DataFrame): ì˜ˆì¸¡ê°’ì´ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        output_dir (Optional[Path]): ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ log í´ë” ì‚¬ìš©)
        filename (Optional[str]): íŒŒì¼ëª… (Noneì´ë©´ ìë™ ìƒì„±)
        logger (Optional[logging.Logger]): ë¡œê±° ê°ì²´
    
    Output:
        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    if output_dir is None:
        script_dir = Path(__file__).parent.parent
        output_dir = script_dir / "log"
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"predictions_{timestamp}.xlsx"
    
    filepath = output_dir / filename
    
    df_with_predictions.to_excel(filepath, index=False, engine='openpyxl')
    
    if logger:
        logger.info(f"ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
    
    return str(filepath)


# ============================================================================
# ë¶„ì„ ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================

def run_analysis_without_preprocessing(
    merged_df_clean: pd.DataFrame,
    graph_file: str,
    treatment: str,
    outcome: str,
    estimator: str,
    logger: Optional[logging.Logger] = None,
    experiment_id: Optional[str] = None,
    job_category: Optional[str] = None
) -> Dict[str, Any]:
    """
    ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ê³¼ì¶”ë¡  ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    (estimation â†’ refutation â†’ predictionë§Œ ìˆ˜í–‰)
    
    Input:
        merged_df_clean (pd.DataFrame): ì „ì²˜ë¦¬ ë° ì •ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        graph_file (str): ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
        treatment (str): ì²˜ì¹˜ ë³€ìˆ˜ëª…
        outcome (str): ê²°ê³¼ ë³€ìˆ˜ëª…
        estimator (str): ì¶”ì • ë°©ë²•
        logger (Optional[logging.Logger]): ë¡œê±° ê°ì²´
        experiment_id (Optional[str]): ì‹¤í—˜ ID (ì„ íƒì )
        job_category (Optional[str]): ì§ì¢…ì†Œë¶„ë¥˜ëª… (checkpoint ì €ì¥ ê²½ë¡œì— ì‚¬ìš©)
    
    Output:
        Dict[str, Any]: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            - status: "success" ë˜ëŠ” "failed"
            - estimate: ì¶”ì •ëœ ì¸ê³¼íš¨ê³¼ ê°ì²´
            - validation_results: ê²€ì¦ ê²°ê³¼
            - sensitivity_df: ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼
            - metrics: ì˜ˆì¸¡ ë©”íŠ¸ë¦­
            - excel_path: ì˜ˆì¸¡ ê²°ê³¼ Excel íŒŒì¼ ê²½ë¡œ
            - step_times: ë‹¨ê³„ë³„ ì†Œìš” ì‹œê°„
            - train_size: í•™ìŠµ ë°ì´í„° í¬ê¸°
            - test_size: í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°
    """
    try:
        from . import estimation
        step_times = {}
        step_start = time.time()
        
        if experiment_id:
            print(f"\n{'='*80}")
            print(f"ì‹¤í—˜ ID: {experiment_id}")
            print(f"ê·¸ë˜í”„: {Path(graph_file).name}")
            print(f"Treatment: {treatment}, Outcome: {outcome}")
            print(f"Estimator: {estimator}")
            print(f"{'='*80}\n")
        
        # 1. ê·¸ë˜í”„ ë¡œë“œ
        print("1ï¸âƒ£ ì¸ê³¼ ê·¸ë˜í”„ ë¡œë“œ ì¤‘...")
        step_start = time.time()
        causal_graph = create_causal_graph(graph_file)
        step_times['ê·¸ë˜í”„ ë¡œë“œ'] = time.time() - step_start
        
        # 2. ë°ì´í„° í•„í„°ë§
        print("2ï¸âƒ£ ê·¸ë˜í”„ ë³€ìˆ˜ì— ë§ê²Œ ë°ì´í„° í•„í„°ë§ ì¤‘...")
        step_start = time.time()
        
        graph_variables = set(causal_graph.nodes())
        data_variables = set(merged_df_clean.columns)
        essential_vars = {treatment, outcome, "SEEK_CUST_NO", "JHNT_CTN", "JHNT_MBN"}
        # HOPE_JSCD3_NAMEì€ ê·¸ë˜í”„ì— í¬í•¨ë˜ì§€ ì•Šì§€ë§Œ ë°ì´í„°ì—ëŠ” ìœ ì§€í•´ì•¼ í•¨
        stratification_vars = {"HOPE_JSCD3_NAME"}
        vars_to_keep = (graph_variables | essential_vars | stratification_vars) & data_variables
        df_for_analysis = merged_df_clean[list(vars_to_keep)].copy()
        
        missing_vars = [var for var in [treatment, outcome] if var not in df_for_analysis.columns]
        if missing_vars:
            raise ValueError(f"í•„ìˆ˜ ë³€ìˆ˜ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {missing_vars}")
        
        step_times['ë°ì´í„° í•„í„°ë§'] = time.time() - step_start
        
        # 3. Train/Test Split
        print("3ï¸âƒ£ Train/Test Split ì¤‘ (1:99)...")
        step_start = time.time()
        
        outcome_data = df_for_analysis[outcome]
        is_binary = outcome_data.nunique() <= 2 and outcome_data.dtype in ['int64', 'int32', 'bool']
        
        if is_binary:
            df_train, df_test = train_test_split(
                df_for_analysis,
                test_size=0.99,  # 1:99 split
                random_state=42,
                stratify=outcome_data
            )
        else:
            df_train, df_test = train_test_split(
                df_for_analysis,
                test_size=0.99,  # 1:99 split
                random_state=42
            )
        
        step_times['Train/Test Split'] = time.time() - step_start
        
        # 4. ì¸ê³¼ëª¨ë¸ ìƒì„±
        print("4ï¸âƒ£ ì¸ê³¼ëª¨ë¸ ìƒì„± ì¤‘...")
        step_start = time.time()
        model = CausalModel(
            data=df_train,
            treatment=treatment,
            outcome=outcome,
            graph=causal_graph
        )
        step_times['ì¸ê³¼ëª¨ë¸ ìƒì„±'] = time.time() - step_start
        
        # 5. ì¸ê³¼íš¨ê³¼ ì‹ë³„
        print("5ï¸âƒ£ ì¸ê³¼íš¨ê³¼ ì‹ë³„ ì¤‘...")
        step_start = time.time()
        identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)
        step_times['ì¸ê³¼íš¨ê³¼ ì‹ë³„'] = time.time() - step_start
        
        # 6. ì¸ê³¼íš¨ê³¼ ì¶”ì •
        print("6ï¸âƒ£ ì¸ê³¼íš¨ê³¼ ì¶”ì • ì¤‘...")
        step_start = time.time()
        estimate = estimation.estimate_causal_effect(
            model,
            identified_estimand,
            estimator,
            logger
        )
        step_times['ì¸ê³¼íš¨ê³¼ ì¶”ì •'] = time.time() - step_start
        
        # 6-1. Checkpoint ì €ì¥ (learning ëª¨ë“œì¼ ë•Œë§Œ)
        checkpoint_path = None
        if experiment_id:
            try:
                # checkpoint ë””ë ‰í† ë¦¬ ê²½ë¡œ ìƒì„± (data/checkpoint)
                script_dir = Path(__file__).parent.parent
                checkpoint_dir = script_dir / "data" / "checkpoint"
                
                # ì§ì¢…ì†Œë¶„ë¥˜ë³„ í´ë” ìƒì„±
                if job_category:
                    job_category_safe = str(job_category).replace("/", "_").replace("\\", "_").replace(" ", "_")
                    checkpoint_dir = checkpoint_dir / job_category_safe
                
                graph_name = Path(graph_file).stem if graph_file else None
                checkpoint_path = estimation.save_checkpoint(
                    estimate,
                    checkpoint_dir,
                    experiment_id,
                    graph_name=graph_name,
                    logger=logger
                )
            except Exception as e:
                if logger:
                    logger.warning(f"Checkpoint ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                print(f"âš ï¸ Checkpoint ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        
        # 7. ì˜ˆì¸¡
        print("7ï¸âƒ£ ì˜ˆì¸¡ ì¤‘...")
        step_start = time.time()
        essential_vars_for_pred = {treatment, outcome}
        # ì˜ˆì¸¡ ì „ì— ì‹¤ì œê°’ ì €ì¥ (ì˜ˆì¸¡ í›„ outcomeì´ ë®ì–´ì”Œì›Œì§€ë¯€ë¡œ)
        if outcome in df_test.columns:
            df_test = df_test.copy()
            df_test[f"{outcome}_actual"] = df_test[outcome].copy()
        
        df_test_clean = clean_dataframe_for_causal_model(
            df_test,
            required_vars=list(essential_vars_for_pred) + [f"{outcome}_actual"] if f"{outcome}_actual" in df_test.columns else list(essential_vars_for_pred),
            logger=logger
        )
        metrics, df_with_predictions = estimation.predict_conditional_expectation(
            estimate, df_test_clean, logger=logger
        )
        step_times['ì˜ˆì¸¡'] = time.time() - step_start
        
        # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
        if experiment_id:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"predictions_{experiment_id}_{timestamp}.xlsx"
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"predictions_{timestamp}.xlsx"
        
        step_start = time.time()
        excel_path = save_predictions_to_excel(df_with_predictions, filename=filename, logger=logger)
        step_times['ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥'] = time.time() - step_start
        
        # 8. ê²€ì¦ í…ŒìŠ¤íŠ¸
        print("8ï¸âƒ£ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        step_start = time.time()
        validation_results = estimation.run_validation_tests(
            model,
            identified_estimand,
            estimate,
            logger
        )
        step_times['ê²€ì¦ í…ŒìŠ¤íŠ¸'] = time.time() - step_start
        
        # 9. ë¯¼ê°ë„ ë¶„ì„
        print("9ï¸âƒ£ ë¯¼ê°ë„ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        step_start = time.time()
        sensitivity_df = estimation.run_sensitivity_analysis(
            model,
            identified_estimand,
            estimate,
            logger
        )
        step_times['ë¯¼ê°ë„ ë¶„ì„'] = time.time() - step_start
        
        # 10. ì‹œê°í™”
        print("ğŸ”Ÿ ì‹œê°í™” ìƒì„± ì¤‘...")
        step_start = time.time()
        heatmap_path = estimation.create_sensitivity_heatmap(
            sensitivity_df,
            logger
        ) if not sensitivity_df.empty else None
        step_times['ì‹œê°í™” ìƒì„±'] = time.time() - step_start
        
        # 11. ìš”ì•½ ë³´ê³ ì„œ
        print("1ï¸âƒ£1ï¸âƒ£ ìµœì¢… ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥ ì¤‘...")
        step_start = time.time()
        estimation.print_summary_report(estimate, validation_results, sensitivity_df)
        step_times['ìš”ì•½ ë³´ê³ ì„œ'] = time.time() - step_start
        
        total_time = sum(step_times.values())
        step_times['ì „ì²´'] = total_time
        
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! (ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ)")
        
        return {
            "status": "success",
            "estimate": estimate,
            "validation_results": validation_results,
            "sensitivity_df": sensitivity_df,
            "metrics": metrics,
            "excel_path": excel_path,
            "checkpoint_path": checkpoint_path,
            "step_times": step_times,
            "train_size": len(df_train),
            "test_size": len(df_test)
        }
        
    except Exception as e:
        if logger:
            logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise


def run_single_experiment(
    merged_df_clean: pd.DataFrame,
    graph_file: str,
    treatment: str,
    outcome: str,
    estimator: str,
    experiment_id: str,
    logger: Optional[logging.Logger] = None,
    split_by_job_category: bool = True
) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ì‹¤í—˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤
    
    Input:
        merged_df_clean (pd.DataFrame): ì „ì²˜ë¦¬ ë° ì •ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        graph_file (str): ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
        treatment (str): ì²˜ì¹˜ ë³€ìˆ˜ëª…
        outcome (str): ê²°ê³¼ ë³€ìˆ˜ëª…
        estimator (str): ì¶”ì • ë°©ë²•
        experiment_id (str): ì‹¤í—˜ ID
        logger (Optional[logging.Logger]): ë¡œê±° ê°ì²´
    
    Output:
        Dict[str, Any]: ì‹¤í—˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            - experiment_id: ì‹¤í—˜ ID
            - status: "success" ë˜ëŠ” "failed"
            - duration_seconds: ì†Œìš” ì‹œê°„ (ì´ˆ)
            - graph: ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
            - graph_name: ê·¸ë˜í”„ íŒŒì¼ëª…
            - treatment: ì²˜ì¹˜ ë³€ìˆ˜ëª…
            - outcome: ê²°ê³¼ ë³€ìˆ˜ëª…
            - estimator: ì¶”ì • ë°©ë²•
            - ate_value: ì¶”ì •ëœ ATE ê°’
            - metrics: ì˜ˆì¸¡ ë©”íŠ¸ë¦­
            - refutation ê²°ê³¼ë“¤ (placebo_passed, unobserved_passed ë“±)
            - excel_path: ì˜ˆì¸¡ ê²°ê³¼ Excel íŒŒì¼ ê²½ë¡œ
            - train_size: í•™ìŠµ ë°ì´í„° í¬ê¸°
            - test_size: í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°
            - start_time: ì‹œì‘ ì‹œê°„
            - end_time: ì¢…ë£Œ ì‹œê°„
            - error: ì˜¤ë¥˜ ë©”ì‹œì§€ (ì‹¤íŒ¨í•œ ê²½ìš°)
    """
    from . import estimation
    start_time = datetime.now()
    try:
        # ì§ì¢…ì†Œë¶„ë¥˜ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì‹¤í—˜ ì‹¤í–‰
        if split_by_job_category and "HOPE_JSCD3_NAME" in merged_df_clean.columns:
            # ì§ì¢…ì†Œë¶„ë¥˜ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬
            job_categories = merged_df_clean["HOPE_JSCD3_NAME"].dropna().unique()
            print(f"ğŸ“Š ì§ì¢…ì†Œë¶„ë¥˜ë³„ ì‹¤í—˜ ì‹¤í–‰: {len(job_categories)}ê°œ ì§ì¢…ì†Œë¶„ë¥˜")
            
            all_results = []
            all_predictions = []
            all_metrics = []
            
            for job_category in job_categories:
                job_df = merged_df_clean[merged_df_clean["HOPE_JSCD3_NAME"] == job_category].copy()
                
                if len(job_df) < 10:  # ìµœì†Œ ë°ì´í„° ìˆ˜ ì²´í¬
                    if logger:
                        logger.warning(f"ì§ì¢…ì†Œë¶„ë¥˜ '{job_category}' ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ ê±´ë„ˆëœë‹ˆë‹¤: {len(job_df)}ê±´")
                    print(f"âš ï¸ ì§ì¢…ì†Œë¶„ë¥˜ '{job_category}' ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ ê±´ë„ˆëœë‹ˆë‹¤: {len(job_df)}ê±´")
                    continue
                
                # ì§ì¢…ì†Œë¶„ë¥˜ë³„ experiment_id ìƒì„±
                job_category_safe = str(job_category).replace("/", "_").replace("\\", "_").replace(" ", "_")
                job_experiment_id = f"{experiment_id}_{job_category_safe}"
                
                print(f"\n  ğŸ”¹ ì§ì¢…ì†Œë¶„ë¥˜: {job_category} ({len(job_df)}ê±´)")
                
                try:
                    job_result = run_analysis_without_preprocessing(
                        merged_df_clean=job_df,
                        graph_file=graph_file,
                        treatment=treatment,
                        outcome=outcome,
                        estimator=estimator,
                        logger=logger,
                        experiment_id=job_experiment_id,
                        job_category=job_category
                    )
                    
                    all_results.append(job_result)
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘
                    if job_result.get("excel_path"):
                        try:
                            pred_df = pd.read_excel(job_result["excel_path"])
                            all_predictions.append(pred_df)
                        except:
                            pass
                    
                    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                    if job_result.get("metrics"):
                        all_metrics.append(job_result["metrics"])
                        
                except Exception as e:
                    if logger:
                        logger.error(f"ì§ì¢…ì†Œë¶„ë¥˜ '{job_category}' ì‹¤í—˜ ì‹¤íŒ¨: {e}")
                    print(f"  âŒ ì§ì¢…ì†Œë¶„ë¥˜ '{job_category}' ì‹¤í—˜ ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  ì§ì¢…ì†Œë¶„ë¥˜ ê²°ê³¼ í†µí•©
            if not all_results:
                raise ValueError("ëª¨ë“  ì§ì¢…ì†Œë¶„ë¥˜ ì‹¤í—˜ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            # ì˜ˆì¸¡ ê²°ê³¼ í•©ì¹˜ê¸°
            if all_predictions:
                combined_predictions = pd.concat(all_predictions, ignore_index=True)
                
                # í†µí•© ë©”íŠ¸ë¦­ ê³„ì‚°
                combined_metrics = {}
                if all_metrics:
                    # Accuracy, F1, AUCëŠ” ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ë¡œ ê³„ì‚°
                    actual_outcome_col = f"{outcome}_actual"
                    if actual_outcome_col in combined_predictions.columns and outcome in combined_predictions.columns:
                        actual_y = combined_predictions[actual_outcome_col]
                        predicted_y = combined_predictions[outcome]  # ì˜ˆì¸¡ê°’
                        
                        if pd.api.types.is_numeric_dtype(actual_y):
                            from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
                            unique_values = set(actual_y.dropna().unique())
                            is_binary = len(unique_values) <= 2 and all(v in [0, 1] for v in unique_values if not pd.isna(v))
                            
                            if is_binary:
                                predicted_classes = (predicted_y > 0.5).astype(int) if pd.api.types.is_numeric_dtype(predicted_y) else predicted_y
                                combined_metrics['accuracy'] = accuracy_score(actual_y, predicted_classes)
                                combined_metrics['f1_score'] = f1_score(actual_y, predicted_classes, zero_division=0)
                                try:
                                    combined_metrics['auc'] = roc_auc_score(actual_y, predicted_y)
                                except:
                                    combined_metrics['auc'] = None
                
                # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                excel_path = save_predictions_to_excel(
                    combined_predictions, 
                    filename=f"predictions_{experiment_id}_combined_{timestamp}.xlsx",
                    logger=logger
                )
            else:
                combined_metrics = {}
                excel_path = None
            
            # ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš© (ATEëŠ” í‰ê·  ê³„ì‚° ê°€ëŠ¥)
            base_result = all_results[0]
            ate_values = [r.get("estimate", {}).get("value") if hasattr(r.get("estimate"), "value") else None 
                         for r in all_results if r.get("estimate")]
            avg_ate = sum([v for v in ate_values if v is not None]) / len([v for v in ate_values if v is not None]) if ate_values else None
            
            result = {
                "status": "success",
                "estimate": base_result.get("estimate"),
                "validation_results": base_result.get("validation_results", {}),
                "sensitivity_df": base_result.get("sensitivity_df"),
                "metrics": combined_metrics,
                "excel_path": excel_path,
                "step_times": base_result.get("step_times", {}),
                "train_size": sum([r.get("train_size", 0) for r in all_results]),
                "test_size": sum([r.get("test_size", 0) for r in all_results]),
                "job_category_results": all_results,
                "num_job_categories": len(all_results)
            }
        else:
            # ì§ì¢…ì†Œë¶„ë¥˜ë³„ ë¶„ë¦¬ ì—†ì´ ê¸°ì¡´ ë°©ì‹
            result = run_analysis_without_preprocessing(
                merged_df_clean=merged_df_clean,
                graph_file=graph_file,
                treatment=treatment,
                outcome=outcome,
                estimator=estimator,
                logger=logger,
                experiment_id=experiment_id
            )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        metrics = result.get("metrics", {})
        estimate = result.get("estimate")
        validation_results = result.get("validation_results", {})
        
        # ATE ê°’ ì¶”ì¶œ
        ate_value = None
        if estimate and hasattr(estimate, 'value'):
            ate_value = estimate.value
        
        # Refutation ê²°ê³¼ ì¶”ì¶œ
        refutation_data = {}
        refutation_types = ['placebo', 'unobserved', 'subset', 'dummy']
        for ref_type in refutation_types:
            ref_result = validation_results.get(ref_type)
            if ref_result is not None:
                if ref_type == 'placebo':
                    effect_change = abs(ref_result.new_effect - ref_result.estimated_effect)
                    refutation_data[f'{ref_type}_passed'] = effect_change < 0.01
                elif ref_type == 'unobserved':
                    change_rate = abs(ref_result.new_effect - ref_result.estimated_effect) / abs(ref_result.estimated_effect) if abs(ref_result.estimated_effect) > 0 else float('inf')
                    refutation_data[f'{ref_type}_passed'] = change_rate < 0.2
                elif ref_type == 'subset':
                    effect_change = abs(ref_result.new_effect - ref_result.estimated_effect)
                    change_rate = abs(ref_result.estimated_effect) > 0 and abs(effect_change / ref_result.estimated_effect) or float('inf')
                    refutation_data[f'{ref_type}_passed'] = change_rate < 0.1
                elif ref_type == 'dummy':
                    refutation_data[f'{ref_type}_passed'] = abs(ref_result.new_effect) < 0.01
                
                p_value = estimation.calculate_refutation_pvalue(ref_result, ref_type)
                refutation_data[f'{ref_type}_pvalue'] = p_value
            else:
                refutation_data[f'{ref_type}_passed'] = None
                refutation_data[f'{ref_type}_pvalue'] = None
        
        return {
            "experiment_id": experiment_id,
            "status": "success",
            "duration_seconds": duration,
            "graph": graph_file,
            "graph_name": Path(graph_file).stem,
            "treatment": treatment,
            "outcome": outcome,
            "estimator": estimator,
            "ate_value": ate_value,
            "metrics": metrics,
            "accuracy": metrics.get("accuracy") if metrics else None,
            "f1_score": metrics.get("f1_score") if metrics else None,
            "auc": metrics.get("auc") if metrics else None,
            "excel_path": result.get("excel_path"),
            "train_size": result.get("train_size"),
            "test_size": result.get("test_size"),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            **refutation_data
        }
    except Exception as e:
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        return {
            "experiment_id": experiment_id,
            "status": "failed",
            "duration_seconds": duration,
            "graph": graph_file,
            "treatment": treatment,
            "outcome": outcome,
            "estimator": estimator,
            "error": str(e),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
        }


def run_inference(
    merged_df_clean: pd.DataFrame,
    graph_file: str,
    checkpoint_dir: Path,
    treatment: str,
    outcome: str,
    estimator: str,
    logger: Optional[logging.Logger] = None,
    experiment_id: Optional[str] = None
) -> Dict[str, Any]:
    """
    Inference ëª¨ë“œ: checkpointì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ì˜ˆì¸¡ë§Œ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    ì§ì¢…ì†Œë¶„ë¥˜ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ checkpointë¥¼ ì°¾ê³  ì˜ˆì¸¡í•œ í›„ í•©ì¹©ë‹ˆë‹¤.
    
    Input:
        merged_df_clean (pd.DataFrame): ì „ì²˜ë¦¬ ë° ì •ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        graph_file (str): ê·¸ë˜í”„ íŒŒì¼ ê²½ë¡œ
        checkpoint_dir (Path): checkpoint ë””ë ‰í† ë¦¬ ê²½ë¡œ
        treatment (str): ì²˜ì¹˜ ë³€ìˆ˜ëª…
        outcome (str): ê²°ê³¼ ë³€ìˆ˜ëª…
        estimator (str): ì¶”ì • ë°©ë²•
        logger (Optional[logging.Logger]): ë¡œê±° ê°ì²´
        experiment_id (Optional[str]): ì‹¤í—˜ ID (ì„ íƒì )
    
    Output:
        Dict[str, Any]: ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            - status: "success" ë˜ëŠ” "failed"
            - metrics: ì˜ˆì¸¡ ë©”íŠ¸ë¦­ (í†µí•©)
            - excel_path: ì˜ˆì¸¡ ê²°ê³¼ Excel íŒŒì¼ ê²½ë¡œ (í†µí•©)
            - step_times: ë‹¨ê³„ë³„ ì†Œìš” ì‹œê°„
    """
    try:
        from . import estimation
        step_times = {}
        step_start = time.time()
        
        if experiment_id:
            print(f"\n{'='*80}")
            print(f"Inference ëª¨ë“œ - ì‹¤í—˜ ID: {experiment_id}")
            print(f"ê·¸ë˜í”„: {Path(graph_file).name}")
            print(f"Treatment: {treatment}, Outcome: {outcome}, Estimator: {estimator}")
            print(f"{'='*80}\n")
        
        graph_name = Path(graph_file).stem
        
        # ì§ì¢…ì†Œë¶„ë¥˜ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì˜ˆì¸¡
        if "HOPE_JSCD3_NAME" in merged_df_clean.columns:
            job_categories = merged_df_clean["HOPE_JSCD3_NAME"].dropna().unique()
            print(f"ğŸ“Š ì§ì¢…ì†Œë¶„ë¥˜ë³„ Inference ì‹¤í–‰: {len(job_categories)}ê°œ ì§ì¢…ì†Œë¶„ë¥˜")
            
            all_predictions = []
            all_metrics = []
            
            for job_category in job_categories:
                job_df = merged_df_clean[merged_df_clean["HOPE_JSCD3_NAME"] == job_category].copy()
                
                if len(job_df) == 0:
                    continue
                
                job_category_safe = str(job_category).replace("/", "_").replace("\\", "_").replace(" ", "_")
                job_checkpoint_dir = checkpoint_dir / job_category_safe
                
                print(f"\n  ğŸ”¹ ì§ì¢…ì†Œë¶„ë¥˜: {job_category} ({len(job_df)}ê±´)")
                
                # í•´ë‹¹ ì§ì¢…ì†Œë¶„ë¥˜ì˜ checkpoint ì°¾ê¸°
                checkpoint_file = estimation.find_checkpoint(
                    job_checkpoint_dir,
                    graph_name,
                    treatment,
                    outcome,
                    estimator,
                    logger
                )
                
                if not checkpoint_file:
                    print(f"  âš ï¸ Checkpointë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤: {job_category}")
                    continue
                
                try:
                    # Checkpointì—ì„œ ëª¨ë¸ ë¡œë“œ
                    estimate = estimation.load_checkpoint(checkpoint_file, logger)
                    
                    # ë°ì´í„° í•„í„°ë§
                    essential_vars = {treatment, outcome, "SEEK_CUST_NO", "JHNT_CTN", "JHNT_MBN"}
                    data_variables = set(job_df.columns)
                    vars_to_keep = essential_vars & data_variables
                    
                    missing_vars = [var for var in [treatment, outcome] if var not in job_df.columns]
                    if missing_vars:
                        print(f"  âš ï¸ í•„ìˆ˜ ë³€ìˆ˜ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤: {missing_vars}")
                        continue
                    
                    df_for_prediction = job_df[list(vars_to_keep)].copy()
                    
                    # ì˜ˆì¸¡ ì „ì— ì‹¤ì œê°’ ì €ì¥ (ì˜ˆì¸¡ í›„ outcomeì´ ë®ì–´ì”Œì›Œì§€ë¯€ë¡œ)
                    if outcome in df_for_prediction.columns:
                        df_for_prediction[f"{outcome}_actual"] = df_for_prediction[outcome].copy()
                    
                    # ì˜ˆì¸¡
                    df_pred_clean = clean_dataframe_for_causal_model(
                        df_for_prediction,
                        required_vars=list(essential_vars) + [f"{outcome}_actual"] if f"{outcome}_actual" in df_for_prediction.columns else list(essential_vars),
                        logger=logger
                    )
                    metrics, df_with_predictions = estimation.predict_conditional_expectation(
                        estimate, df_pred_clean, logger=logger
                    )
                    
                    all_predictions.append(df_with_predictions)
                    if metrics:
                        all_metrics.append(metrics)
                    
                    print(f"  âœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(df_with_predictions)}ê±´")
                    
                except Exception as e:
                    print(f"  âŒ ì§ì¢…ì†Œë¶„ë¥˜ '{job_category}' ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    if logger:
                        logger.error(f"ì§ì¢…ì†Œë¶„ë¥˜ '{job_category}' ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  ì§ì¢…ì†Œë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ í•©ì¹˜ê¸°
            if not all_predictions:
                raise ValueError("ëª¨ë“  ì§ì¢…ì†Œë¶„ë¥˜ ì˜ˆì¸¡ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            combined_predictions = pd.concat(all_predictions, ignore_index=True)
            
            # í†µí•© ë©”íŠ¸ë¦­ ê³„ì‚°
            combined_metrics = {}
            actual_outcome_col = f"{outcome}_actual"
            if actual_outcome_col in combined_predictions.columns and outcome in combined_predictions.columns:
                actual_y = combined_predictions[actual_outcome_col]
                predicted_y = combined_predictions[outcome]  # ì˜ˆì¸¡ê°’
                
                if pd.api.types.is_numeric_dtype(actual_y):
                    from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
                    unique_values = set(actual_y.dropna().unique())
                    is_binary = len(unique_values) <= 2 and all(v in [0, 1] for v in unique_values if not pd.isna(v))
                    
                    if is_binary:
                        predicted_classes = (predicted_y > 0.5).astype(int) if pd.api.types.is_numeric_dtype(predicted_y) else predicted_y
                        valid_mask = ~(pd.isna(actual_y) | pd.isna(predicted_classes))
                        if valid_mask.sum() > 0:
                            combined_metrics['accuracy'] = accuracy_score(actual_y[valid_mask], predicted_classes[valid_mask])
                            combined_metrics['f1_score'] = f1_score(actual_y[valid_mask], predicted_classes[valid_mask], zero_division=0)
                            try:
                                combined_metrics['auc'] = roc_auc_score(actual_y[valid_mask], predicted_y[valid_mask])
                            except:
                                combined_metrics['auc'] = None
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
            step_start = time.time()
            if experiment_id:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"predictions_inference_{experiment_id}_combined_{timestamp}.xlsx"
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"predictions_inference_combined_{timestamp}.xlsx"
            
            excel_path = save_predictions_to_excel(combined_predictions, filename=filename, logger=logger)
            step_times['ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥'] = time.time() - step_start
            
        else:
            # HOPE_JSCD3_NAMEì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ (ë‹¨ì¼ checkpoint)
            raise ValueError("HOPE_JSCD3_NAME ë³€ìˆ˜ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ì§ì¢…ì†Œë¶„ë¥˜ë³„ ë¶„ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        total_time = sum(step_times.values())
        step_times['ì „ì²´'] = total_time
        
        print(f"\nâœ… Inference ì™„ë£Œ! (ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ)")
        if combined_metrics:
            print(f"   Accuracy: {combined_metrics.get('accuracy', 'N/A')}")
            print(f"   F1 Score: {combined_metrics.get('f1_score', 'N/A')}")
            print(f"   AUC: {combined_metrics.get('auc', 'N/A')}")
        
        return {
            "status": "success",
            "metrics": combined_metrics,
            "excel_path": excel_path,
            "step_times": step_times,
            "data_size": len(combined_predictions)
        }
        
    except Exception as e:
        if logger:
            logger.error(f"Inference ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ Inference ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise


# ============================================================================
# ì„¤ì • íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
# ============================================================================

def load_config(config_path: Path) -> Dict[str, Any]:
    """
    ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤
    
    Input:
        config_path (Path): ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON í˜•ì‹)
    
    Output:
        Dict[str, Any]: ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    return config

