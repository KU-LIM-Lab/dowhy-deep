{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb7949e",
   "metadata": {},
   "source": [
    "\n",
    "# **Unconstructed Preprocessor**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca10fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os, json, re\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Tuple, Iterable\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class UnconstructedPreprocessor:\n",
    "    # -------------------- Helpers --------------------\n",
    "    DATE_FMT = \"%Y-%m-%d\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_date(s: Optional[str]) -> Optional[datetime]:\n",
    "        if s in (None, \"\", \"null\"):\n",
    "            return None\n",
    "        try:\n",
    "            return datetime.strptime(str(s)[:10], UnconstructedPreprocessor.DATE_FMT)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _days_between(d1: Optional[datetime], d2: Optional[datetime]) -> Optional[int]:\n",
    "        if d1 is None or d2 is None:\n",
    "            return None\n",
    "        return (d1 - d2).days\n",
    "\n",
    "    @staticmethod\n",
    "    def _estimate_typos_korean(text: str) -> int:\n",
    "        if not text:\n",
    "            return 0\n",
    "        dbl_spaces = len(re.findall(r\" {2,}\", text))\n",
    "        repeat_punct = len(re.findall(r\"([\\.?!,~\\-])\\1{2,}\", text))\n",
    "        latin_tokens = re.findall(r\"\\b[A-Za-z]{2,}\\b\", text)\n",
    "        return dbl_spaces + repeat_punct + len(latin_tokens)\n",
    "\n",
    "    @staticmethod\n",
    "    def _file_exists(p: Path) -> bool:\n",
    "        try:\n",
    "            return p.exists() and p.is_file()\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def _resolve_any(base_dir: Path, candidates: Iterable[str]) -> Path:\n",
    "        \"\"\"Try exact, json/, and recursive search under base_dir.\"\"\"\n",
    "        for c in candidates:\n",
    "            p = Path(c)\n",
    "            if p.is_absolute() and UnconstructedPreprocessor._file_exists(p):\n",
    "                return p\n",
    "            if UnconstructedPreprocessor._file_exists(base_dir / c):\n",
    "                return (base_dir / c)\n",
    "            if UnconstructedPreprocessor._file_exists(base_dir / \"json\" / c):\n",
    "                return (base_dir / \"json\" / c)\n",
    "        # recursive: try last candidate's basename\n",
    "        for c in candidates:\n",
    "            name = Path(c).name\n",
    "            matches = list(base_dir.rglob(name))\n",
    "            for m in matches:\n",
    "                if UnconstructedPreprocessor._file_exists(m):\n",
    "                    return m\n",
    "        # if still not found, raise helpful error\n",
    "        tried = []\n",
    "        for c in candidates:\n",
    "            tried.extend([str(Path(c)), str(base_dir / c), str(base_dir / \"json\" / c), f\"{str(base_dir)}/**/{Path(c).name}\"])\n",
    "        raise FileNotFoundError(f\"다음 경로에서 파일을 찾지 못했습니다:\\n\" + \"\\n\".join(tried))\n",
    "\n",
    "    # -------------------- LLM --------------------\n",
    "    HR_SYSTEM = \"\"\"당신은 채용 담당자입니다.\n",
    "입력으로 주어진 '지원자 자료'가 '목표 직종'에 얼마나 적합한지 0~100으로 평가하세요.\n",
    "- 90~100: 직무핵심 역량과 직접 연결, 최근 경력/훈련/성과가 뚜렷\n",
    "- 70~89: 관련성이 높고 실무 연결고리가 충분\n",
    "- 40~69: 부분 관련. 기초 역량은 있으나 연결고리/증거가 부족\n",
    "- 10~39: 간접적, 전환 가능성은 있으나 근거 약함\n",
    "- 0~9: 관련 근거 없음\n",
    "반드시 JSON으로 답변: {\\\"score\\\": int, \\\"rationale\\\": \\\"짧은 이유\\\"}\"\"\"\n",
    "\n",
    "    FEWSHOT = {\n",
    "        \"자기소개서\": [\n",
    "            {\"input\":{\"job\":\"데이터 분석가\",\"text\":\"통계학 전공, 머신러닝 프로젝트 다수 수행, Python/SQL/시각화로 성과 수치 제시\"},\n",
    "             \"output\":{\"score\":95,\"rationale\":\"핵심 역량, 실무 성과 구체적\"}},\n",
    "            {\"input\":{\"job\":\"프론트엔드 개발자\",\"text\":\"React/TypeScript 기반 대시보드 개발, 성능 최적화로 LCP 40% 개선\"},\n",
    "             \"output\":{\"score\":93,\"rationale\":\"직접 성능 개선 성과\"}},\n",
    "            {\"input\":{\"job\":\"회계\",\"text\":\"K-IFRS 재무제표 작성, 결산/세무조정, 전표 처리 자동화 경험\"},\n",
    "             \"output\":{\"score\":90,\"rationale\":\"핵심 실무 지식\"}},\n",
    "        ],\n",
    "        \"이력서\": [\n",
    "            {\"input\":{\"job\":\"데이터 엔지니어\",\"text\":\"데이터 파이프라인 운영, Spark SQL 튜닝, Kafka 스트리밍 구축\"},\n",
    "             \"output\":{\"score\":92,\"rationale\":\"프로덕션 파이프라인 경험\"}},\n",
    "            {\"input\":{\"job\":\"마케팅 분석가\",\"text\":\"퍼포먼스 캠페인 ROI 분석, 리타게팅 최적화\"},\n",
    "             \"output\":{\"score\":88,\"rationale\":\"분석/성과 근거\"}},\n",
    "        ],\n",
    "        \"직업훈련\": [\n",
    "            {\"input\":{\"job\":\"데이터 분석가\",\"text\":\"빅데이터 분석(파이썬/SQL/머신러닝) 수료, 팀 프로젝트 산출물\"},\n",
    "             \"output\":{\"score\":85,\"rationale\":\"핵심 커리큘럼 수료\"}},\n",
    "            {\"input\":{\"job\":\"프론트엔드 개발자\",\"text\":\"React/Next.js 심화, 테스트/성능 최적화 모듈\"},\n",
    "             \"output\":{\"score\":82,\"rationale\":\"현업 연계 과정\"}},\n",
    "        ],\n",
    "        \"자격증\": [\n",
    "            {\"input\":{\"job\":\"데이터 분석가\",\"text\":\"ADsP, SQLD, 빅데이터분석기사\"},\n",
    "             \"output\":{\"score\":88,\"rationale\":\"핵심 자격 보유\"}},\n",
    "            {\"input\":{\"job\":\"회계\",\"text\":\"전산회계1급, FAT\"},\n",
    "             \"output\":{\"score\":86,\"rationale\":\"직무 핵심 자격\"}},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def _offline_score(section: str, text: str, job_examples: List[str]) -> Tuple[int,str]:\n",
    "        if not text or text.strip() == \"정보 없음\":\n",
    "            return 10, \"자료 부족\"\n",
    "        keywords = [\n",
    "            '데이터','분석','SQL','파이썬','머신','시각화','대시보드','A/B','통계','모델','예측',\n",
    "            'React','TypeScript','API','Spring','배포','ETL','Spark','Kafka','Airflow',\n",
    "            '회계','결산','세무','채용','온보딩','GA4','ROI','엑셀','보고서','대학','경력'\n",
    "        ]\n",
    "        hits = sum(1 for k in keywords if k.lower() in text.lower())\n",
    "        base = 45\n",
    "        return min(95, base + hits*5), f\"키워드 {hits}개 매칭\"\n",
    "\n",
    "    def _build_prompt(self, section: str, job_name: str, job_examples: List[str], text: str) -> str:\n",
    "        import json as _json\n",
    "        def shot(s):\n",
    "            return f\"[예시]\\\\n직무: {s['input']['job']}\\\\n자료:\\\\n{s['input']['text']}\\\\n=> {_json.dumps(s['output'], ensure_ascii=False)}\"\n",
    "        examples = \"\\\\n\\\\n\".join(shot(s) for s in self.FEWSHOT.get(section, []))\n",
    "        job_hint = f\"참고 직무 예시: {', '.join(job_examples[:12])}\" if job_examples else \"참고 직무 예시: 없음\"\n",
    "        return f\"\"\"[평가 섹션] {section}\n",
    "[목표 직종] {job_name}\n",
    "{job_hint}\n",
    "\n",
    "{examples}\n",
    "\n",
    "[지원자 자료]\n",
    "{text}\n",
    "\n",
    "[응답 형식] JSON 한 줄 ({{\"score\": 0-100 정수, \"rationale\": \"간단한 이유\"}})\n",
    "\"\"\"\n",
    "\n",
    "    def _score_with_llm(self, section: str, job_name: str, job_examples: List[str], text: str) -> Tuple[int,str]:\n",
    "        if not self.api_key:\n",
    "            return self._offline_score(section, text, job_examples)\n",
    "        try:\n",
    "            os.environ[\"OPENAI_API_KEY\"] = self.api_key\n",
    "            from openai import OpenAI\n",
    "            client = OpenAI()\n",
    "            sys_msg = {\"role\":\"system\",\"content\": self.HR_SYSTEM}\n",
    "            user_msg = {\"role\":\"user\",\"content\": self._build_prompt(section, job_name, job_examples, text)}\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[sys_msg, user_msg],\n",
    "                temperature=0.2,\n",
    "                response_format={\"type\":\"json_object\"},\n",
    "            )\n",
    "            content = resp.choices[0].message.content\n",
    "            import json as _json\n",
    "            data = _json.loads(content)\n",
    "            score = int(max(0, min(100, int(data.get(\"score\", 0)))))\n",
    "            why = str(data.get(\"rationale\", \"\"))[:240]\n",
    "            return score, why\n",
    "        except Exception:\n",
    "            return self._offline_score(section, text, job_examples)\n",
    "\n",
    "    # -------------------- Init --------------------\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_dir: str,\n",
    "        coverletters_file: str = \"COVERLETTERS_JSON.json\",\n",
    "        trainings_file: str = \"TRAININGS_JSON.json\",\n",
    "        licenses_file: str = \"LICENSES_JSON.json\",\n",
    "        resume_file: str = \"RESUME_JSON.json\",\n",
    "        certinfo_file: str = \"CERTIFICATION_INFO_JSON.json\",\n",
    "        job_excel_file: Optional[str] = \"2025-직종 분류표.xlsx\",\n",
    "        job_csv_file: Optional[str] = \"job_subcategories.csv\",\n",
    "        api_key: Optional[str] = None,\n",
    "        max_cover_len: int = 800,\n",
    "        cover_exceed_ratio: float = 0.85,\n",
    "        allowed_seek_ids: Optional[List[str]] = None,\n",
    "    ):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.api_key = api_key\n",
    "        self.max_cover_len = max_cover_len\n",
    "        self.cover_exceed_ratio = cover_exceed_ratio\n",
    "        self.allowed_seek_ids = set(allowed_seek_ids) if allowed_seek_ids else None\n",
    "\n",
    "        # resolve files (exact, json/, recursive)\n",
    "        self.coverletters_path = self._resolve_any(self.base_dir, [coverletters_file])\n",
    "        self.trainings_path    = self._resolve_any(self.base_dir, [trainings_file])\n",
    "        self.licenses_path     = self._resolve_any(self.base_dir, [licenses_file])\n",
    "        self.resume_path       = self._resolve_any(self.base_dir, [resume_file])\n",
    "        self.certinfo_path     = self._resolve_any(self.base_dir, [certinfo_file])\n",
    "\n",
    "        # load jsons\n",
    "        self.coverletters = json.load(open(self.coverletters_path, encoding=\"utf-8\"))\n",
    "        self.trainings    = json.load(open(self.trainings_path,    encoding=\"utf-8\"))\n",
    "        self.licenses     = json.load(open(self.licenses_path,     encoding=\"utf-8\"))\n",
    "        self.resumes      = json.load(open(self.resume_path,       encoding=\"utf-8\"))\n",
    "        self.certinfo     = json.load(open(self.certinfo_path,     encoding=\"utf-8\"))\n",
    "\n",
    "        # job classification\n",
    "        self.jobmap = pd.DataFrame(columns=[\"소분류코드\",\"소분류명\",\"세분류명\"])\n",
    "        used_job = False\n",
    "        if job_excel_file:\n",
    "            try:\n",
    "                p = self._resolve_any(self.base_dir, [job_excel_file])\n",
    "                xls = pd.ExcelFile(p)\n",
    "                df_raw = pd.read_excel(xls, xls.sheet_names[0])\n",
    "                records, current_sub_code, current_sub_name = [], None, None\n",
    "                for _, row in df_raw.iterrows():\n",
    "                    sub_code = row.get(\"Unnamed: 4\"); sub_name = row.get(\"Unnamed: 5\")\n",
    "                    code = row.get(\"Unnamed: 6\"); jobname = row.get(\"Unnamed: 7\")\n",
    "                    if pd.notna(sub_code):\n",
    "                        current_sub_code = str(int(sub_code)) if isinstance(sub_code,(int,float)) else str(sub_code).strip()\n",
    "                        current_sub_name = str(sub_name).strip() if pd.notna(sub_name) else \"\"\n",
    "                        continue\n",
    "                    if pd.notna(code) and pd.notna(jobname) and current_sub_code:\n",
    "                        records.append({\"소분류코드\": current_sub_code, \"소분류명\": current_sub_name, \"세분류명\": str(jobname).strip()})\n",
    "                if records:\n",
    "                    self.jobmap = pd.DataFrame(records).groupby([\"소분류코드\",\"소분류명\"])[\"세분류명\"].apply(list).reset_index()\n",
    "                    used_job = True\n",
    "            except FileNotFoundError:\n",
    "                used_job = False\n",
    "        if not used_job and job_csv_file:\n",
    "            try:\n",
    "                p = self._resolve_any(self.base_dir, [job_csv_file])\n",
    "                df = pd.read_csv(p)\n",
    "                if \"세분류명\" in df.columns and df[\"세분류명\"].apply(lambda x: isinstance(x, str) and x.startswith(\"[\")).any():\n",
    "                    df[\"세분류명\"] = df[\"세분류명\"].apply(lambda s: eval(s) if isinstance(s,str) else [])\n",
    "                self.jobmap = df[[\"소분류코드\",\"소분류명\",\"세분류명\"]].copy()\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        self.js_lookup = {str(r[\"소분류코드\"]).strip(): r[\"세분류명\"] for _, r in self.jobmap.iterrows()}\n",
    "        self.js_name   = {str(r[\"소분류코드\"]).strip(): r[\"소분류명\"] for _, r in self.jobmap.iterrows()}\n",
    "\n",
    "        # indices\n",
    "        self.seek_to_jhnt, self.jhnt_to_seek, self.seek_to_jhcr_de, self.seek_to_hope = {}, {}, {}, {}\n",
    "        for row in self.certinfo:\n",
    "            seek = row.get(\"SEEK_CUST_NO\"); jhnt = row.get(\"JHNT_CTN\")\n",
    "            if seek:\n",
    "                self.seek_to_hope[seek] = (row.get(\"HOPE_JSCD1\") or \"\")\n",
    "                if row.get(\"JHCR_DE\"): self.seek_to_jhcr_de[seek] = row.get(\"JHCR_DE\")\n",
    "            if seek and jhnt:\n",
    "                self.seek_to_jhnt[seek] = jhnt\n",
    "                self.jhnt_to_seek[jhnt] = seek\n",
    "\n",
    "        self.jhnt_trainings = {row.get(\"JHNT_CTN\"): row.get(\"TRAININGS\", []) for row in self.trainings}\n",
    "        self.jhnt_licenses  = {row.get(\"JHNT_CTN\"): row.get(\"LICENSES\",  []) for row in self.licenses}\n",
    "        self.seek_coverletters = {row.get(\"SEEK_CUST_NO\"): row.get(\"COVERLETTERS\", []) for row in self.coverletters}\n",
    "        self.seek_resumes      = {row.get(\"SEEK_CUST_NO\"): row.get(\"RESUMES\",       []) for row in self.resumes}\n",
    "\n",
    "    # -------------------- Universe --------------------\n",
    "    def _seek_ids(self) -> List[str]:\n",
    "        ids = [row.get(\"SEEK_CUST_NO\") for row in self.certinfo if row.get(\"SEEK_CUST_NO\")]\n",
    "        if self.allowed_seek_ids is not None:\n",
    "            ids = [i for i in ids if i in self.allowed_seek_ids]\n",
    "        return sorted(set(ids))\n",
    "\n",
    "    def _hope_info(self, seek_id: str) -> Tuple[str, str, List[str]]:\n",
    "        hope = str(self.seek_to_hope.get(seek_id) or \"\").strip()\n",
    "        job_name = self.js_name.get(hope, f\"소분류 {hope}\") if hope else \"미상\"\n",
    "        job_examples = self.js_lookup.get(hope, [])\n",
    "        return hope, job_name, job_examples\n",
    "\n",
    "    # -------------------- RESUME Parsing (rules) --------------------\n",
    "    def _build_resume_sections(self, seek_id: str) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        sections = {\n",
    "            \"학력\": [], \"개인경력\": [], \"봉사활동\": [],\n",
    "            \"논문\": [], \"수상경력\": [], \"참여프로젝트\": [],\n",
    "            \"훈련통합\": [], \"해외연수\": [], \"외국어능력\": [],\n",
    "            \"전산자격통합\": []\n",
    "        }\n",
    "        for resume in self.seek_resumes.get(seek_id, []):\n",
    "            for it in (resume.get(\"ITEMS\") or []):\n",
    "                sec = it.get(\"RESUME_ITEM_CLCD_NM\") or it.get(\"DS_RESUME_ITEM_CLCD\") or \"\"\n",
    "                nm  = it.get(\"RESUME_ITEM_1_NM\") or \"\"\n",
    "                val = it.get(\"RESUME_ITEM_1_VAL\") or \"\"\n",
    "                st  = it.get(\"HIST_STDT\") or \"\"\n",
    "                en  = it.get(\"HIST_ENDT\") or \"\"\n",
    "                rec = {\"sec\":sec,\"name\":nm,\"value\":val,\"start\":st,\"end\":en}\n",
    "                sec_norm = sec.replace(\" \", \"\") if isinstance(sec, str) else sec\n",
    "                if sec_norm in [\"학력\",\"개인경력\",\"봉사활동\",\"논문\",\"수상경력\",\"참여프로젝트\",\"해외연수\",\"외국어능력\",\"전산능력\",\"자격면허\",\"훈련\",\"직업훈련\"]:\n",
    "                    if sec_norm in [\"전산능력\",\"자격면허\"]:\n",
    "                        sections[\"전산자격통합\"].append(rec)\n",
    "                    elif sec_norm in [\"훈련\",\"직업훈련\"]:\n",
    "                        sections[\"훈련통합\"].append(rec)\n",
    "                    else:\n",
    "                        sections[sec_norm].append(rec)\n",
    "        return sections\n",
    "\n",
    "    # -------------------- Sections (numeric + qualitative) --------------------\n",
    "    def process_coverletters(self, seek_id: str) -> Dict[str, Any]:\n",
    "        texts = []\n",
    "        items = []\n",
    "        for c in self.seek_coverletters.get(seek_id, []):\n",
    "            if str(c.get(\"BASS_SFID_YN\",\"\")).upper()==\"Y\":\n",
    "                items = c.get(\"ITEMS\", []) or []\n",
    "                for it in items:\n",
    "                    t = it.get(\"SELF_INTRO_CONT\") or \"\"\n",
    "                    if t: texts.append(t.strip())\n",
    "                break\n",
    "        full_text = \"\\n\\n\".join(texts) if texts else \"정보 없음\"\n",
    "        lens = [len(it.get(\"SELF_INTRO_CONT\") or \"\") for it in items] if items else []\n",
    "        max_len = max(lens) if lens else 0\n",
    "        typo = sum(self._estimate_typos_korean(it.get(\"SELF_INTRO_CONT\") or \"\") for it in items) if items else 0\n",
    "\n",
    "        hope, job_name, job_examples = self._hope_info(seek_id)\n",
    "        score, why = self._score_with_llm(\"자기소개서\", job_name, job_examples, full_text)\n",
    "        return {\n",
    "            \"SEEK_CUST_NO\": seek_id,\n",
    "            \"HOPE_JSCD1\": hope, \"HOPE_JOB_NAME\": job_name,\n",
    "            \"cover_items_count\": len(items),\n",
    "            \"cover_max_chars\": max_len,\n",
    "            \"cover_exceed_85pct\": int(max_len >= self.max_cover_len * self.cover_exceed_ratio),\n",
    "            \"cover_typo_count\": typo,\n",
    "            \"cover_score\": score, \"cover_why\": why\n",
    "        }\n",
    "\n",
    "    def process_resume(self, seek_id: str) -> Dict[str, Any]:\n",
    "        secs = self._build_resume_sections(seek_id)\n",
    "\n",
    "        # Numeric summaries\n",
    "        def _count(key): return len(secs.get(key, []))\n",
    "        edu_cnt = _count(\"학력\")\n",
    "        exp_cnt = _count(\"개인경력\")\n",
    "        vol_cnt = _count(\"봉사활동\")\n",
    "        pap_cnt = _count(\"논문\")\n",
    "        awd_cnt = _count(\"수상경력\")\n",
    "        prj_cnt = _count(\"참여프로젝트\")\n",
    "        trn_cnt = _count(\"훈련통합\")\n",
    "        ov_cnt  = _count(\"해외연수\")\n",
    "        lang_cnt= _count(\"외국어능력\")\n",
    "        itc_cnt = _count(\"전산자격통합\")\n",
    "\n",
    "        # Sum experience duration (days)\n",
    "        def _sum_days(items):\n",
    "            total = 0\n",
    "            for r in items:\n",
    "                d1 = self._parse_date(r.get(\"end\"))\n",
    "                d2 = self._parse_date(r.get(\"start\"))\n",
    "                if d1 and d2:\n",
    "                    total += self._days_between(d1, d2) or 0\n",
    "            return total\n",
    "        exp_days = _sum_days(secs.get(\"개인경력\", []))\n",
    "\n",
    "        # Build text block following rules\n",
    "        lines = []\n",
    "        def add_block(title, arr, formatter=lambda r: f\"{r.get('name') or r.get('value')} ({r.get('start')}~{r.get('end')})\"):\n",
    "            if not arr: return\n",
    "            lines.append(f\"[{title}]\")\n",
    "            for r in arr:\n",
    "                if title==\"논문\":\n",
    "                    nm = r.get(\"name\") or r.get(\"value\")\n",
    "                    body = r.get(\"value\") if r.get(\"name\") else \"\"\n",
    "                    lines.append(f\"- {nm}: {body} ({r.get('start')}~{r.get('end')})\")\n",
    "                else:\n",
    "                    lines.append(f\"- {formatter(r)}\")\n",
    "\n",
    "        add_block(\"학력\", secs.get(\"학력\", []))\n",
    "        add_block(\"개인경력\", secs.get(\"개인경력\", []))\n",
    "        add_block(\"봉사활동\", secs.get(\"봉사활동\", []))\n",
    "        add_block(\"참여프로젝트\", secs.get(\"참여프로젝트\", []))\n",
    "        add_block(\"수상경력\", secs.get(\"수상경력\", []))\n",
    "        add_block(\"논문\", secs.get(\"논문\", []))\n",
    "        add_block(\"훈련·직업훈련(통합)\", secs.get(\"훈련통합\", []))\n",
    "        add_block(\"해외연수\", secs.get(\"해외연수\", []), formatter=lambda r: f\"{r.get('value') or r.get('name')} ({r.get('start')}~{r.get('end')})\")\n",
    "        add_block(\"외국어능력\", secs.get(\"외국어능력\", []))\n",
    "        add_block(\"전산능력+자격면허(통합)\", secs.get(\"전산자격통합\", []))\n",
    "\n",
    "        text = \"\\n\".join(lines) if lines else \"정보 없음\"\n",
    "\n",
    "        hope, job_name, job_examples = self._hope_info(seek_id)\n",
    "        score, why = self._score_with_llm(\"이력서\", job_name, job_examples, text)\n",
    "        return {\n",
    "            \"SEEK_CUST_NO\": seek_id, \"HOPE_JSCD1\": hope, \"HOPE_JOB_NAME\": job_name,\n",
    "            \"edu_count\": edu_cnt, \"exp_count\": exp_cnt, \"exp_days\": exp_days,\n",
    "            \"vol_count\": vol_cnt, \"paper_count\": pap_cnt, \"award_count\": awd_cnt,\n",
    "            \"project_count\": prj_cnt, \"training_resume_count\": trn_cnt,\n",
    "            \"overseas_count\": ov_cnt, \"lang_count\": lang_cnt, \"it_comp_license_count\": itc_cnt,\n",
    "            \"resume_score\": score, \"resume_why\": why\n",
    "        }\n",
    "\n",
    "    def process_trainings(self, seek_id: str) -> Dict[str, Any]:\n",
    "        secs = self._build_resume_sections(seek_id)\n",
    "        resume_train = secs.get(\"훈련통합\", [])\n",
    "\n",
    "        jhnt = self.seek_to_jhnt.get(seek_id)\n",
    "        tr_json = self.jhnt_trainings.get(jhnt, []) if jhnt else []\n",
    "\n",
    "        def _to_rec_from_json(t):\n",
    "            return {\"name\": t.get(\"TRNG_NM\") or \"\", \"start\": t.get(\"TRNG_BGDE\") or \"\", \"end\": t.get(\"TRNG_ENDE\") or \"\"}\n",
    "        def _to_rec_from_resume(t):\n",
    "            return {\"name\": t.get(\"name\") or t.get(\"value\") or \"\", \"start\": t.get(\"start\") or \"\", \"end\": t.get(\"end\") or \"\"}\n",
    "\n",
    "        combined = [ _to_rec_from_json(t) for t in tr_json ] + [ _to_rec_from_resume(t) for t in resume_train ]\n",
    "\n",
    "        seen = set(); uniq = []\n",
    "        for r in combined:\n",
    "            key = (r[\"name\"], r[\"start\"], r[\"end\"])\n",
    "            if key not in seen:\n",
    "                seen.add(key); uniq.append(r)\n",
    "\n",
    "        ends = [self._parse_date(r[\"end\"]) for r in uniq if r.get(\"end\")]\n",
    "        ends = [d for d in ends if d]\n",
    "        last_end = max(ends).strftime(self.DATE_FMT) if ends else None\n",
    "        jobseek = self.seek_to_jhcr_de.get(seek_id)\n",
    "        gap = self._days_between(self._parse_date(jobseek), self._parse_date(last_end)) if (jobseek and last_end) else None\n",
    "\n",
    "        text = \"\\n\".join([f\"{r['name']} ({r['start']}~{r['end']})\" for r in uniq]) if uniq else \"정보 없음\"\n",
    "\n",
    "        hope, job_name, job_examples = self._hope_info(seek_id)\n",
    "        score, why = self._score_with_llm(\"직업훈련\", job_name, job_examples, text)\n",
    "        return {\n",
    "            \"SEEK_CUST_NO\": seek_id, \"HOPE_JSCD1\": hope, \"HOPE_JOB_NAME\": job_name,\n",
    "            \"training_count_total\": len(uniq),\n",
    "            \"training_last_end\": last_end,\n",
    "            \"jobseek_date\": jobseek,\n",
    "            \"days_last_training_to_jobseek\": gap,\n",
    "            \"training_score\": score, \"training_why\": why\n",
    "        }\n",
    "\n",
    "    def process_licenses(self, seek_id: str) -> Dict[str, Any]:\n",
    "        secs = self._build_resume_sections(seek_id)\n",
    "        resume_itlic = secs.get(\"전산자격통합\", [])\n",
    "\n",
    "        jhnt = self.seek_to_jhnt.get(seek_id)\n",
    "        lic_json = self.jhnt_licenses.get(jhnt, []) if jhnt else []\n",
    "\n",
    "        def _to_rec_from_json(l):\n",
    "            return {\"cat\": l.get(\"QULF_LCNS_LCFN\") or \"\", \"name\": l.get(\"QULF_LCNS_NM\") or \"\", \"acq\": l.get(\"ACQ_DE\") or \"\"}\n",
    "        def _to_rec_from_resume(l):\n",
    "            return {\"cat\": l.get(\"sec\") or \"\", \"name\": l.get(\"name\") or l.get(\"value\") or \"\", \"acq\": l.get(\"end\") or \"\"}\n",
    "\n",
    "        combined = [ _to_rec_from_json(l) for l in lic_json ] + [ _to_rec_from_resume(l) for l in resume_itlic ]\n",
    "\n",
    "        seen = set(); uniq = []\n",
    "        for r in combined:\n",
    "            key = (r[\"cat\"], r[\"name\"], r[\"acq\"])\n",
    "            if key not in seen:\n",
    "                seen.add(key); uniq.append(r)\n",
    "\n",
    "        cats = [r[\"cat\"] for r in uniq if r.get(\"cat\")]\n",
    "        cnt = Counter(cats) if cats else Counter()\n",
    "        has_nat_tech = int(cnt.get(\"국가기술자격\", 0) > 0)\n",
    "        has_nat_prof = int(cnt.get(\"국가전문자격\", 0) > 0)\n",
    "        has_priv     = int(cnt.get(\"민간자격\", 0) > 0)\n",
    "        top_cat = None\n",
    "        if cnt:\n",
    "            top_cat = sorted(cnt.items(), key=lambda kv: (-kv[1], kv[0]))[0][0]\n",
    "\n",
    "        text = \"\\n\".join([f\"{r['cat']} - {r['name']} (취득:{r['acq']})\" for r in uniq]) if uniq else \"정보 없음\"\n",
    "\n",
    "        hope, job_name, job_examples = self._hope_info(seek_id)\n",
    "        score, why = self._score_with_llm(\"자격증\", job_name, job_examples, text)\n",
    "        return {\n",
    "            \"SEEK_CUST_NO\": seek_id, \"HOPE_JSCD1\": hope, \"HOPE_JOB_NAME\": job_name,\n",
    "            \"license_total\": len(uniq),\n",
    "            \"has_국가기술자격\": has_nat_tech,\n",
    "            \"has_국가전문자격\": has_nat_prof,\n",
    "            \"has_민간자격\": has_priv,\n",
    "            \"top_license_category\": top_cat,\n",
    "            \"license_score\": score, \"license_why\": why\n",
    "        }\n",
    "\n",
    "    # -------------------- Build & Save --------------------\n",
    "    def build_section_df(self, section: str) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        for seek in self._seek_ids():\n",
    "            if section == \"coverletters\":\n",
    "                rows.append(self.process_coverletters(seek))\n",
    "            elif section == \"resume\":\n",
    "                rows.append(self.process_resume(seek))\n",
    "            elif section == \"trainings\":\n",
    "                rows.append(self.process_trainings(seek))\n",
    "            elif section == \"licenses\":\n",
    "                rows.append(self.process_licenses(seek))\n",
    "        return pd.DataFrame(rows).sort_values(\"SEEK_CUST_NO\").reset_index(drop=True)\n",
    "\n",
    "    def save_all_sections(self, out_dir: str | Path) -> Dict[str, Path]:\n",
    "        out_dir = Path(out_dir)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        outputs = {}\n",
    "        mapping = {\n",
    "            \"coverletters\": \"coverletters_metrics_scores.csv\",\n",
    "            \"resume\": \"resume_metrics_scores.csv\",\n",
    "            \"trainings\": \"trainings_metrics_scores.csv\",\n",
    "            \"licenses\": \"licenses_metrics_scores.csv\",\n",
    "        }\n",
    "        for sec, fname in mapping.items():\n",
    "            df = self.build_section_df(sec)\n",
    "            p = out_dir / fname\n",
    "            df.to_csv(p, index=False, encoding=\"utf-8-sig\")\n",
    "            outputs[sec] = p\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae2d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverletters': PosixPath('/Users/jongrakjeong/Library/Mobile Documents/com~apple~CloudDocs/Study/Campus/Project/laborlab/coverletters_metrics_scores.csv'), 'resume': PosixPath('/Users/jongrakjeong/Library/Mobile Documents/com~apple~CloudDocs/Study/Campus/Project/laborlab/resume_metrics_scores.csv'), 'trainings': PosixPath('/Users/jongrakjeong/Library/Mobile Documents/com~apple~CloudDocs/Study/Campus/Project/laborlab/trainings_metrics_scores.csv'), 'licenses': PosixPath('/Users/jongrakjeong/Library/Mobile Documents/com~apple~CloudDocs/Study/Campus/Project/laborlab/licenses_metrics_scores.csv')}\n"
     ]
    }
   ],
   "source": [
    "BASE = '/Users/jongrakjeong/Library/Mobile Documents/com~apple~CloudDocs/Study/Campus/Project/laborlab'\n",
    "\n",
    "pre = UnconstructedPreprocessor(\n",
    "    base_dir=BASE,\n",
    "    coverletters_file=\"/json/COVERLETTERS_JSON.json\",\n",
    "    trainings_file=\"/json/TRAININGS_JSON.json\",\n",
    "    licenses_file=\"/json/LICENSES_JSON.json\",\n",
    "    resume_file=\"/json/RESUME_JSON.json\",\n",
    "    certinfo_file=\"/json/CERTIFICATION_INFO_JSON.json\",\n",
    "    job_csv_file=\"job_subcategories.csv\",\n",
    "    api_key=None\n",
    "    cover_exceed_ratio=0.85,\n",
    "    allowed_seek_ids=None\n",
    ")\n",
    "\n",
    "out_paths = pre.save_all_sections(BASE)\n",
    "print(out_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76679743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
