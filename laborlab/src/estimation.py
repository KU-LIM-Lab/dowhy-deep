"""
DoWhy ì¸ê³¼íš¨ê³¼ ì¶”ì • ë° ê²€ì¦ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ì¸ê³¼íš¨ê³¼ ì¶”ì •, ê²€ì¦ í…ŒìŠ¤íŠ¸, ë¯¼ê°ë„ ë¶„ì„ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import logging
from pathlib import Path
from datetime import datetime
import os
import sys

from dowhy.causal_estimators.regression_estimator import RegressionEstimator

# ë¡œì»¬ DoWhy ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..'))

# DoWhy ë‚´ë¶€ í•¨ìˆ˜ ì„í¬íŠ¸
from dowhy.causal_estimator import estimate_effect as dowhy_estimate_effect

def log_estimation_results(logger, estimate, method_name):
    """
    ì¶”ì • ê²°ê³¼ë¥¼ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        logger: ë¡œê±° ê°ì²´
        estimate: ì¶”ì •ëœ ì¸ê³¼íš¨ê³¼ ê°ì²´
        method_name (str): ì¶”ì • ë°©ë²•ëª…
    """
    logger.info("="*60)
    logger.info("ì¸ê³¼ íš¨ê³¼ ì¶”ì • ê²°ê³¼")
    logger.info("="*60)
    logger.info(f"ì¶”ì • ë°©ë²•: {method_name}")
    logger.info(f"ì¶”ì •ëœ ì¸ê³¼ íš¨ê³¼ (ATE): {estimate.value:.6f}")
    
    if hasattr(estimate, 'p_value') and estimate.p_value is not None:
        logger.info(f"P-value: {estimate.p_value:.6f}")
        significance = "ìœ ì˜í•¨" if estimate.p_value <= 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ"
        logger.info(f"í†µê³„ì  ìœ ì˜ì„±: {significance}")
    
    # ì¶”ì •ì¹˜ì˜ ì‹ ë¢°êµ¬ê°„ì´ ìˆë‹¤ë©´ ë¡œê¹…
    if hasattr(estimate, 'confidence_intervals'):
        logger.info(f"ì‹ ë¢°êµ¬ê°„: {estimate.confidence_intervals}")


def predict_conditional_expectation(estimate, data_df, treatment_value=None, logger=None):
    """
    E(Y|A, X) ì¡°ê±´ë¶€ ê¸°ëŒ€ê°’ ì˜ˆì¸¡
    
    Args:
        estimate: CausalEstimate ê°ì²´
        data_df: ì˜ˆì¸¡í•  ë°ì´í„°í”„ë ˆì„
        treatment_value: ì²˜ì¹˜ ê°’ (Noneì´ë©´ ì‹¤ì œ ê°’ ì‚¬ìš©)
        logger: ë¡œê±° ê°ì²´
    
    Returns:
        tuple: (data_df_with_predictions, accuracy)
            - data_df_with_predictions: ACQ_180_YN ì—´ì— ì˜ˆì¸¡ê°’ì´ ì±„ì›Œì§„ ë°ì´í„°í”„ë ˆì„
            - accuracy: ì •í™•ë„ (ì´ì§„ ë¶„ë¥˜) ë˜ëŠ” None (ì—°ì†í˜•)
    """
    if not hasattr(estimate, 'estimator'):
        raise ValueError("estimate.estimatorê°€ ì—†ìŠµë‹ˆë‹¤. estimate_causal_effectë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    
    estimator = estimate.estimator
    if not isinstance(estimator, RegressionEstimator):
        raise ValueError(f"{type(estimator).__name__}ëŠ” ì˜ˆì¸¡ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    if logger:
        logger.info(f"E(Y|A, X) ì˜ˆì¸¡ ì‹œì‘: {len(data_df)}ê°œ")
        if treatment_value is not None:
            logger.info(f"ì²˜ì¹˜ ê°’: {treatment_value}")
    
    try:
        if treatment_value is not None:
            predictions = estimator.interventional_outcomes(data_df, treatment_value)
        else:
            predictions = estimator.predict(data_df)
        
        predictions_series = pd.Series(predictions, index=data_df.index)
        
        # ë°ì´í„°í”„ë ˆì„ ë³µì‚¬ í›„ ì˜ˆì¸¡ê°’ ì±„ìš°ê¸°
        result_df = data_df.copy()
        outcome_name = estimate.outcome_name
        result_df[outcome_name] = predictions_series
        
        # ì‹¤ì œ Y ê°’ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ ê³„ì‚°
        outcome_name = estimate.outcome_name
        accuracy = 0
        if outcome_name in data_df.columns:
            actual_y = data_df[outcome_name]
            predicted_classes = (predictions_series > 0.5).astype(int)
            accuracy = (predicted_classes == actual_y).mean()
            if logger:
                logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: ì •í™•ë„={accuracy:.4f} ({accuracy*100:.2f}%)")
        else:
            if logger:
                logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: í‰ê· ={predictions_series.mean():.6f}")
                logger.warning(f"ì‹¤ì œ Y ê°’({outcome_name})ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì •í™•ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return accuracy, result_df
        
    except Exception as e:
        if logger:
            logger.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        raise

def estimate_causal_effect(model, identified_estimand, estimator, logger=None):
    """ì¸ê³¼íš¨ê³¼ë¥¼ ì¶”ì •í•˜ëŠ” í•¨ìˆ˜"""
    if logger:
        logger.info("="*60)
        logger.info("ì¸ê³¼íš¨ê³¼ ì¶”ì • ì‹œì‘")
        logger.info("="*60)
    
    method_map = {
        'linear_regression': 'backdoor.linear_regression',
        'tabpfn': 'backdoor.tabpfn',
        'propensity_score': 'backdoor.propensity_score_stratification',
        'instrumental_variable': 'iv.instrumental_variable'
    }
    
    method = method_map.get(estimator, 'backdoor.linear_regression')
    
    if logger:
        logger.info(f"ì‚¬ìš©í•  ì¶”ì • ë°©ë²•: {method}")
        logger.info(f"ìš”ì²­ëœ ì¶”ì •ê¸°: {estimator}")
    
    try:
        # TabPFNì˜ ê²½ìš° íŠ¹ë³„í•œ íŒŒë¼ë¯¸í„° ì„¤ì • (legacy ë²„ì „ ì‚¬ìš©)
        if estimator == 'tabpfn':
            from dowhy.causal_estimators.tabpfn_estimator_legacy import TabpfnEstimator
            # tabpfn_estimator_legacyëŠ” DoWhyì˜ í‘œì¤€ naming conventionê³¼ ë‹¤ë¥´ë¯€ë¡œ
            # ì§ì ‘ estimator ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ DoWhyì˜ estimate_effect í•¨ìˆ˜ì— ì „ë‹¬
            tabpfn_estimator = TabpfnEstimator(
                identified_estimand,
                test_significance=True,
                method_params={
                    "N_ensemble_configurations": 8
                }
            )
            # DoWhyì˜ estimate_effect í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ
            estimate = dowhy_estimate_effect(
                data=model._data,
                treatment=model._treatment,
                outcome=model._outcome,
                identifier_name="backdoor",
                estimator=tabpfn_estimator,
                control_value=0,
                treatment_value=1,
                target_units="ate",
                effect_modifiers=model._graph.get_effect_modifiers(model._treatment, model._outcome),
                fit_estimator=True,
                method_params={}
            )
        else:
            estimate = model.estimate_effect(
                identified_estimand,
                method_name=method,
                test_significance=True
            )
        
        if logger:
            logger.info("âœ… ì¸ê³¼íš¨ê³¼ ì¶”ì • ì„±ê³µ")
            logger.info(f"ì¶”ì •ëœ ì¸ê³¼ íš¨ê³¼ (ATE): {estimate.value:.6f}")
            if hasattr(estimate, 'p_value') and estimate.p_value is not None:
                logger.info(f"P-value: {estimate.p_value:.6f}")
                significance = "ìœ ì˜í•¨" if estimate.p_value <= 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ"
                logger.info(f"í†µê³„ì  ìœ ì˜ì„±: {significance}")
            
            # ì‹ ë¢°êµ¬ê°„ ì •ë³´
            if hasattr(estimate, 'confidence_intervals'):
                logger.info(f"ì‹ ë¢°êµ¬ê°„: {estimate.confidence_intervals}")
        
        return estimate
        
    except Exception as e:
        if logger:
            logger.error(f"âŒ ì¸ê³¼íš¨ê³¼ ì¶”ì • ì‹¤íŒ¨: {e}")
        raise

def log_validation_results(logger, validation_results):
    """
    ê²€ì¦ ê²°ê³¼ë¥¼ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        logger: ë¡œê±° ê°ì²´
        validation_results (dict): ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    logger.info("="*60)
    logger.info("ê²€ì¦ ê²°ê³¼ ìš”ì•½")
    logger.info("="*60)
    
    # ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸
    if validation_results.get('placebo'):
        placebo = validation_results['placebo']
        effect_change = abs(placebo.new_effect - placebo.estimated_effect)
        status = "í†µê³¼" if effect_change < 0.01 else "ì‹¤íŒ¨"
        logger.info(f"ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸: {status}")
        logger.info(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {placebo.estimated_effect:.6f}")
        logger.info(f"  - ê°€ìƒì²˜ì¹˜ í›„ ì¶”ì •ì¹˜: {placebo.new_effect:.6f}")
        logger.info(f"  - íš¨ê³¼ ë³€í™”: {effect_change:.6f}")
    
    # ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸
    if validation_results.get('unobserved'):
        unobserved = validation_results['unobserved']
        change_rate = abs(unobserved.new_effect - unobserved.estimated_effect) / abs(unobserved.estimated_effect)
        status = "ê°•ê±´í•¨" if change_rate < 0.2 else "ë¯¼ê°í•¨"
        logger.info(f"ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸: {status}")
        logger.info(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {unobserved.estimated_effect:.6f}")
        logger.info(f"  - êµë€ ì¶”ê°€ í›„ ì¶”ì •ì¹˜: {unobserved.new_effect:.6f}")
        logger.info(f"  - ë³€í™”ìœ¨: {change_rate:.2%}")
    
    # ë¶€ë¶„í‘œë³¸ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
    if validation_results.get('subset'):
        subset = validation_results['subset']
        logger.info(f"ë¶€ë¶„í‘œë³¸ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸:")
        logger.info(f"  - ê¸°ì¡´ ì¶”ì •ì¹˜: {subset.estimated_effect:.6f}")
        logger.info(f"  - ë¶€ë¶„í‘œë³¸ ì¶”ì •ì¹˜: {subset.new_effect:.6f}")
    
    # ë”ë¯¸ ê²°ê³¼ í…ŒìŠ¤íŠ¸
    if validation_results.get('dummy'):
        dummy = validation_results['dummy']
        status = "í†µê³¼" if abs(dummy.new_effect) < 0.01 else "ì‹¤íŒ¨"
        logger.info(f"ë”ë¯¸ ê²°ê³¼ í…ŒìŠ¤íŠ¸: {status}")
        logger.info(f"  - ë”ë¯¸ ê²°ê³¼ ì¶”ì •ì¹˜: {dummy.new_effect:.6f}")

def run_validation_tests(model, identified_estimand, estimate, logger=None):
    """ê²€ì¦ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    if logger:
        logger.info("="*60)
        logger.info("ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œì‘")
        logger.info("="*60)
    
    validation_results = {}
    
    # ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸
    if logger:
        logger.info("1ï¸âƒ£ ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    
    try:
        refute_placebo = model.refute_estimate(
            identified_estimand, estimate,
            method_name="placebo_treatment_refuter",
            placebo_type="permute",
            num_simulations=100
        )
        validation_results['placebo'] = refute_placebo
        
        if logger:
            logger.info("âœ… ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            effect_change = abs(refute_placebo.new_effect - refute_placebo.estimated_effect)
            status = "í†µê³¼" if effect_change < 0.01 else "ì‹¤íŒ¨"
            logger.info(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {status}")
            logger.info(f"ê¸°ì¡´ ì¶”ì •ì¹˜: {refute_placebo.estimated_effect:.6f}")
            logger.info(f"ê°€ìƒì²˜ì¹˜ í›„ ì¶”ì •ì¹˜: {refute_placebo.new_effect:.6f}")
            logger.info(f"íš¨ê³¼ ë³€í™”: {effect_change:.6f}")
            
    except Exception as e:
        validation_results['placebo'] = None
        if logger:
            logger.error(f"âŒ ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    # ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸
    if logger:
        logger.info("2ï¸âƒ£ ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    
    try:
        refute_unobserved = model.refute_estimate(
            identified_estimand, estimate,
            method_name="add_unobserved_common_cause",
            confounders_effect_on_treatment="binary_flip",
            confounders_effect_on_outcome="linear",
            effect_strength_on_treatment=0.10,
            effect_strength_on_outcome=0.10,
            num_simulations=100
        )
        validation_results['unobserved'] = refute_unobserved
        
        if logger:
            logger.info("âœ… ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            change_rate = abs(refute_unobserved.new_effect - refute_unobserved.estimated_effect) / abs(refute_unobserved.estimated_effect)
            status = "ê°•ê±´í•¨" if change_rate < 0.2 else "ë¯¼ê°í•¨"
            logger.info(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {status}")
            logger.info(f"ê¸°ì¡´ ì¶”ì •ì¹˜: {refute_unobserved.estimated_effect:.6f}")
            logger.info(f"êµë€ ì¶”ê°€ í›„ ì¶”ì •ì¹˜: {refute_unobserved.new_effect:.6f}")
            logger.info(f"ë³€í™”ìœ¨: {change_rate:.2%}")
            
    except Exception as e:
        validation_results['unobserved'] = None
        if logger:
            logger.error(f"âŒ ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    if logger:
        logger.info("="*60)
        logger.info("ê²€ì¦ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        logger.info("="*60)
    
    return validation_results

def log_sensitivity_analysis(logger, sensitivity_df, config):
    """
    ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        logger: ë¡œê±° ê°ì²´
        sensitivity_df (pd.DataFrame): ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼
        config (dict): ë¯¼ê°ë„ ë¶„ì„ ì„¤ì •
    """
    logger.info("="*60)
    logger.info("ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼")
    logger.info("="*60)
    
    logger.info(f"íš¨ê³¼ ê°•ë„ ë²”ìœ„: {config['effect_strength_range'][0]} ~ {config['effect_strength_range'][1]}")
    logger.info(f"ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ ìˆ˜: {config['num_points']}")
    logger.info(f"ì‹œë®¬ë ˆì´ì…˜ ìˆ˜: {config['num_simulations']}")
    logger.info(f"ë¶„ì„ëœ ì¡°í•© ìˆ˜: {len(sensitivity_df)}")
    
    if not sensitivity_df.empty:
        logger.info(f"íš¨ê³¼ ë²”ìœ„: {sensitivity_df['new_effect'].min():.6f} ~ {sensitivity_df['new_effect'].max():.6f}")
        
        # íš¨ê³¼ê°€ 0ì— ê°€ê¹Œìš´ ì§€ì  ì°¾ê¸°
        min_abs_effect = sensitivity_df.loc[sensitivity_df['new_effect'].abs().idxmin()]
        logger.info(f"ìµœì†Œ ì ˆëŒ€ íš¨ê³¼ ì§€ì :")
        logger.info(f"  - ì²˜ì¹˜ ê°•ë„ (et): {min_abs_effect['effect_strength_on_treatment']:.2f}")
        logger.info(f"  - ê²°ê³¼ ê°•ë„ (eo): {min_abs_effect['effect_strength_on_outcome']:.2f}")
        logger.info(f"  - íš¨ê³¼ê°’: {min_abs_effect['new_effect']:.6f}")
        
        # íš¨ê³¼ê°€ ìŒìˆ˜ì¸ ì¡°í•© ìˆ˜
        negative_effects = len(sensitivity_df[sensitivity_df['new_effect'] < 0])
        logger.info(f"ìŒìˆ˜ íš¨ê³¼ ì¡°í•© ìˆ˜: {negative_effects} ({negative_effects/len(sensitivity_df)*100:.1f}%)")
        
        # íš¨ê³¼ê°€ 0ì— ê°€ê¹Œìš´ ì¡°í•© ìˆ˜ (ì ˆëŒ€ê°’ < 0.01)
        near_zero_effects = len(sensitivity_df[sensitivity_df['new_effect'].abs() < 0.01])
        logger.info(f"0ì— ê°€ê¹Œìš´ íš¨ê³¼ ì¡°í•© ìˆ˜: {near_zero_effects} ({near_zero_effects/len(sensitivity_df)*100:.1f}%)")

def run_sensitivity_analysis(model, identified_estimand, estimate, config, logger=None):
    """
    ë¯¼ê°ë„ ë¶„ì„ì„ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        model: CausalModel ê°ì²´
        identified_estimand: ì‹ë³„ëœ ì¶”ì •ëŸ‰ ê°ì²´
        estimate: ì¶”ì •ëœ ì¸ê³¼íš¨ê³¼ ê°ì²´
        config (dict): ë¯¼ê°ë„ ë¶„ì„ ì„¤ì •
        logger: ë¡œê±° ê°ì²´ (ì„ íƒì‚¬í•­)
    
    Returns:
        pd.DataFrame: ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
    """
    try:
        effect_range = config['effect_strength_range']
        num_points = config['num_points']
        num_simulations = config['num_simulations']
        
        grid = np.linspace(effect_range[0], effect_range[1], num_points)
        
        rows = []
        for i, et in enumerate(grid):
            for j, eo in enumerate(grid):
                try:
                    ref = model.refute_estimate(
                        identified_estimand, estimate,
                        method_name="add_unobserved_common_cause",
                        confounders_effect_on_treatment="binary_flip",
                        confounders_effect_on_outcome="linear",
                        effect_strength_on_treatment=et,
                        effect_strength_on_outcome=eo,
                        num_simulations=num_simulations
                    )
                    rows.append((et, eo, ref.new_effect))
                except Exception as e:
                    rows.append((et, eo, np.nan))
                    if logger:
                        logger.warning(f"ë¯¼ê°ë„ ë¶„ì„ ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ ({et}, {eo}) ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        sensitivity_df = pd.DataFrame(rows, columns=[
            "effect_strength_on_treatment", 
            "effect_strength_on_outcome", 
            "new_effect"
        ])
        
        if logger:
            log_sensitivity_analysis(logger, sensitivity_df, config)
        
        return sensitivity_df
        
    except Exception as e:
        if logger:
            logger.error(f"ë¯¼ê°ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

def log_heatmap_info(logger, heatmap_path, config):
    """
    íˆíŠ¸ë§µ ì •ë³´ë¥¼ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        logger: ë¡œê±° ê°ì²´
        heatmap_path (str): íˆíŠ¸ë§µ íŒŒì¼ ê²½ë¡œ
        config (dict): ì‹œê°í™” ì„¤ì •
    """
    logger.info("="*60)
    logger.info("ì‹œê°í™” ê²°ê³¼")
    logger.info("="*60)
    
    if heatmap_path and os.path.exists(heatmap_path):
        file_size = os.path.getsize(heatmap_path)
        logger.info(f"íˆíŠ¸ë§µ íŒŒì¼: {heatmap_path}")
        logger.info(f"íŒŒì¼ í¬ê¸°: {file_size:,} bytes")
        logger.info(f"ì´ë¯¸ì§€ í•´ìƒë„: {config['figsize'][0]}x{config['figsize'][1]} inches")
        logger.info(f"DPI: {config['dpi']}")
    else:
        logger.warning("íˆíŠ¸ë§µ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def run_sensitivity_analysis(model, identified_estimand, estimate, logger=None):
    """ë¯¼ê°ë„ ë¶„ì„ì„ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    if logger:
        logger.info("="*60)
        logger.info("ë¯¼ê°ë„ ë¶„ì„ ì‹¤í–‰ ì‹œì‘")
        logger.info("="*60)
        logger.info("íš¨ê³¼ ê°•ë„ ë²”ìœ„: 0.0 ~ 0.5")
        logger.info("ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ ìˆ˜: 11x11 = 121ê°œ")
        logger.info("ì‹œë®¬ë ˆì´ì…˜ ìˆ˜: 200íšŒ")
    
    try:
        grid = np.linspace(0.0, 0.5, 11)
        rows = []
        total_combinations = len(grid) * len(grid)
        processed = 0
        
        if logger:
            logger.info(f"ì´ {total_combinations}ê°œ ì¡°í•© ë¶„ì„ ì‹œì‘...")
        
        for i, et in enumerate(grid):
            for j, eo in enumerate(grid):
                processed += 1
                if logger and processed % 20 == 0:
                    logger.info(f"ì§„í–‰ë¥ : {processed}/{total_combinations} ({processed/total_combinations*100:.1f}%)")
                
                try:
                    ref = model.refute_estimate(
                        identified_estimand, estimate,
                        method_name="add_unobserved_common_cause",
                        confounders_effect_on_treatment="binary_flip",
                        confounders_effect_on_outcome="linear",
                        effect_strength_on_treatment=et,
                        effect_strength_on_outcome=eo,
                        num_simulations=200
                    )
                    rows.append((et, eo, ref.new_effect))
                except Exception as e:
                    rows.append((et, eo, np.nan))
                    if logger:
                        logger.warning(f"ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ ({et:.2f}, {eo:.2f}) ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        sensitivity_df = pd.DataFrame(rows, columns=[
            "effect_strength_on_treatment", 
            "effect_strength_on_outcome", 
            "new_effect"
        ])
        
        if logger:
            logger.info("âœ… ë¯¼ê°ë„ ë¶„ì„ ì™„ë£Œ")
            logger.info(f"ë¶„ì„ëœ ì¡°í•© ìˆ˜: {len(sensitivity_df)}")
            
            if not sensitivity_df.empty:
                valid_effects = sensitivity_df.dropna()
                logger.info(f"ìœ íš¨í•œ ê²°ê³¼ ìˆ˜: {len(valid_effects)}")
                logger.info(f"íš¨ê³¼ ë²”ìœ„: {valid_effects['new_effect'].min():.6f} ~ {valid_effects['new_effect'].max():.6f}")
                
                # íš¨ê³¼ê°€ 0ì— ê°€ê¹Œìš´ ì§€ì  ì°¾ê¸°
                min_abs_effect = valid_effects.loc[valid_effects['new_effect'].abs().idxmin()]
                logger.info(f"ìµœì†Œ ì ˆëŒ€ íš¨ê³¼ ì§€ì : et={min_abs_effect['effect_strength_on_treatment']:.2f}, eo={min_abs_effect['effect_strength_on_outcome']:.2f}")
                logger.info(f"ìµœì†Œ ì ˆëŒ€ íš¨ê³¼ê°’: {min_abs_effect['new_effect']:.6f}")
                
                # ìŒìˆ˜ íš¨ê³¼ ë¹„ìœ¨
                negative_effects = len(valid_effects[valid_effects['new_effect'] < 0])
                logger.info(f"ìŒìˆ˜ íš¨ê³¼ ì¡°í•©: {negative_effects}ê°œ ({negative_effects/len(valid_effects)*100:.1f}%)")
        
        return sensitivity_df
        
    except Exception as e:
        if logger:
            logger.error(f"âŒ ë¯¼ê°ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def create_sensitivity_heatmap(sensitivity_df, logger=None):
    """ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ë¥¼ íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
    if logger:
        logger.info("="*60)
        logger.info("íˆíŠ¸ë§µ ìƒì„± ì‹œì‘")
        logger.info("="*60)
    
    if sensitivity_df.empty:
        if logger:
            logger.warning("âŒ ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆì–´ íˆíŠ¸ë§µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        if logger:
            logger.info("í”¼ë²— í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„±
        pivot = sensitivity_df.pivot(
            index="effect_strength_on_treatment",
            columns="effect_strength_on_outcome",
            values="new_effect"
        ).sort_index(ascending=True)
        
        if logger:
            logger.info(f"í”¼ë²— í…Œì´ë¸” í¬ê¸°: {pivot.shape}")
            logger.info("íˆíŠ¸ë§µ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        # íˆíŠ¸ë§µ ìƒì„±
        fig, ax = plt.subplots(figsize=(10, 8), dpi=100)
        
        im = ax.imshow(
            pivot.values,
            origin="lower",
            aspect="auto",
            extent=[
                pivot.columns.min(), pivot.columns.max(),
                pivot.index.min(), pivot.index.max()
            ],
            cmap='RdYlBu_r'
        )
        
        # ìƒ‰ìƒë§‰ëŒ€ ì¶”ê°€
        cbar = plt.colorbar(im, ax=ax)
        cbar.set_label("New Effect (after unobserved confounding)", fontsize=12)
        
        # 0-ì»¨íˆ¬ì–´ ë¼ì¸ ì¶”ê°€
        X, Y = np.meshgrid(pivot.columns.values, pivot.index.values)
        CS = ax.contour(X, Y, pivot.values, levels=[0.0], linewidths=2, colors='black')
        ax.clabel(CS, inline=True, fmt="effect=0", fontsize=10)
        
        # ì¶• ë ˆì´ë¸” ë° ì œëª©
        ax.set_xlabel("Effect Strength on Outcome (eo)", fontsize=12)
        ax.set_ylabel("Effect Strength on Treatment (et)", fontsize=12)
        ax.set_title("Sensitivity Analysis: Effect of Unobserved Confounders", fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        if logger:
            logger.info("íˆíŠ¸ë§µ ì €ì¥ ì¤‘...")
        
        # ê·¸ë¦¼ ì €ì¥
        script_dir = Path(__file__).parent.parent
        log_dir = script_dir / "log"
        log_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"sensitivity_heatmap_{timestamp}.png"
        output_path = log_dir / filename
        
        plt.savefig(output_path, dpi=100, bbox_inches='tight')
        
        if logger:
            logger.info("âœ… íˆíŠ¸ë§µ ìƒì„± ì„±ê³µ")
            logger.info(f"ì €ì¥ ê²½ë¡œ: {output_path}")
            
            # íŒŒì¼ ì •ë³´
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path)
                logger.info(f"íŒŒì¼ í¬ê¸°: {file_size:,} bytes")
                logger.info(f"ì´ë¯¸ì§€ í•´ìƒë„: 10x8 inches, DPI: 100")
        
        return output_path
        
    except Exception as e:
        if logger:
            logger.error(f"âŒ íˆíŠ¸ë§µ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def print_summary_report(estimate, validation_results, sensitivity_df):
    """
    ì „ì²´ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        estimate: ì¶”ì •ëœ ì¸ê³¼íš¨ê³¼ ê°ì²´
        validation_results (dict): ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        sensitivity_df (pd.DataFrame): ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼
    """
    print("\n" + "="*80)
    print("ğŸ“‹ ìµœì¢… ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œ")
    print("="*80)
    
    # ê¸°ë³¸ ì¶”ì • ê²°ê³¼
    print(f"\nğŸ¯ ì£¼ìš” ì¶”ì • ê²°ê³¼:")
    print(f"  - ì¶”ì •ëœ ì¸ê³¼ íš¨ê³¼ (ATE): {estimate.value:.6f}")
    if hasattr(estimate, 'p_value') and estimate.p_value is not None:
        significance = "ìœ ì˜í•¨" if estimate.p_value <= 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ"
        print(f"  - í†µê³„ì  ìœ ì˜ì„±: {significance} (p-value: {estimate.p_value:.6f})")
    
    # ê²€ì¦ ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ”¬ ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
    
    if validation_results.get('placebo'):
        placebo = validation_results['placebo']
        effect_change = abs(placebo.new_effect - placebo.estimated_effect)
        print(f"  - ê°€ìƒ ì›ì¸ í…ŒìŠ¤íŠ¸: {'í†µê³¼' if effect_change < 0.01 else 'ì‹¤íŒ¨'}")
    
    if validation_results.get('unobserved'):
        unobserved = validation_results['unobserved']
        change_rate = abs(unobserved.new_effect - unobserved.estimated_effect) / abs(unobserved.estimated_effect)
        print(f"  - ë¯¸ê´€ì¸¡ êµë€ í…ŒìŠ¤íŠ¸: {'ê°•ê±´í•¨' if change_rate < 0.2 else 'ë¯¼ê°í•¨'}")
    
    if validation_results.get('subset'):
        subset = validation_results['subset']
        print(f"  - ë¶€ë¶„í‘œë³¸ ì•ˆì •ì„±: ì¶”ì •ì¹˜ ë³€í™” í™•ì¸ë¨")
    
    if validation_results.get('dummy'):
        dummy = validation_results['dummy']
        print(f"  - ë”ë¯¸ ê²°ê³¼ í…ŒìŠ¤íŠ¸: {'í†µê³¼' if abs(dummy.new_effect) < 0.01 else 'ì‹¤íŒ¨'}")
    
    # ë¯¼ê°ë„ ë¶„ì„ ìš”ì•½
    if not sensitivity_df.empty:
        print(f"\nğŸ“ˆ ë¯¼ê°ë„ ë¶„ì„ ìš”ì•½:")
        print(f"  - ë¶„ì„ëœ ì¡°í•© ìˆ˜: {len(sensitivity_df)}")
        print(f"  - íš¨ê³¼ ë²”ìœ„: {sensitivity_df['new_effect'].min():.6f} ~ {sensitivity_df['new_effect'].max():.6f}")
        
        # íš¨ê³¼ê°€ 0ì— ê°€ê¹Œìš´ ì§€ì  ì°¾ê¸°
        min_abs_effect = sensitivity_df.loc[sensitivity_df['new_effect'].abs().idxmin()]
        print(f"  - ìµœì†Œ ì ˆëŒ€ íš¨ê³¼ ì§€ì : et={min_abs_effect['effect_strength_on_treatment']:.2f}, eo={min_abs_effect['effect_strength_on_outcome']:.2f}")
    
    print(f"\nâœ… ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
